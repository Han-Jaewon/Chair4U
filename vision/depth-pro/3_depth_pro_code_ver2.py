import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors
from matplotlib.colors import LinearSegmentedColormap
import cv2
from PIL import Image
import depth_pro
from scipy.ndimage import gaussian_filter, median_filter
from scipy.interpolate import griddata
import json
import logging
import time
import gc
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union, Callable, cast
from tqdm import tqdm

# PyTorch ì„í¬íŠ¸
try:
    import torch
    import torchvision.transforms as transforms
    TORCH_AVAILABLE = True
except ImportError as e:
    raise ImportError(f"PyTorch ì„¤ì¹˜ í•„ìš”: {e}")

# ===== ì„¤ì • =====
CONFIG = {
    "base_dir": Path(r"C:\Users\grace\OneDrive\Desktop\dataset"),
    # ê¸°ë³¸ ì…ë ¥ í´ë”ëª…
    "input_folder_base": "padding1536",             
    # ê¸°ë³¸ ì¶œë ¥ í´ë”ëª…
    "output_folder_base": "depth",           
    "subdirs": ["women", "men", "validation"],              
    # í•˜ìœ„ í´ë”
    "depthpro_base_dir": Path(r"C:\Users\grace\OneDrive\Desktop\depth_pro"),
    "checkpoint_path": Path(r"C:\Users\grace\OneDrive\Desktop\depth_pro\checkpoints\depth_pro.pt"),
    "force_cuda": True,
    "enable_memory_optimization": True,
    "gc_frequency": 5,
    "save_visualization": True,
    "save_metadata": True,
}

# ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í˜•ì‹
SUPPORTED_FORMATS = {'.jpg', '.png'}

class DepthProOfficialVisualizer:
    def __init__(self, device="cuda"):
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if CONFIG.get("force_cuda", False) and torch.cuda.is_available():
            self.device = torch.device("cuda")
        else:
            self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        
        # DepthPro ê²½ë¡œ ì„¤ì •
        self._setup_depthpro_paths()
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        if CONFIG["enable_memory_optimization"]:
            self._optimize_gpu_memory()
        
        # ëª¨ë¸ ê´€ë ¨ ë³€ìˆ˜ - íƒ€ì… íŒíŠ¸ ì¶”ê°€
        self.model: Optional[torch.nn.Module] = None
        self.transform: Optional[Union[transforms.Compose, Callable[[Any], torch.Tensor]]] = None
        self.model_loaded: bool = False
        self.processed_count: int = 0
        
        self.official_colormaps = {
            'depthpro_default': 'magma',
            'depthpro_alternative': 'plasma',
            'scientific_standard': 'viridis',
            'boundary_enhanced': 'inferno',
            'publication_safe': 'cividis'
        }
        
        # Apple ê³µì‹ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ
        self._load_model_official()
    
    def _setup_depthpro_paths(self) -> None:
        """DepthPro ê²½ë¡œ ì„¤ì • ë° ê²€ì¦"""
        depthpro_base = CONFIG["depthpro_base_dir"]
        checkpoint_path = CONFIG["checkpoint_path"]
        
        # DepthPro ì„¤ì¹˜ ê²½ë¡œ í™•ì¸
        if not depthpro_base.exists():
            logging.error(f"DepthPro ê¸°ë³¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {depthpro_base}")
            raise FileNotFoundError(f"DepthPro directory not found: {depthpro_base}")
        
        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í™•ì¸
        if not checkpoint_path.exists():
            logging.error(f"DepthPro ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
            raise FileNotFoundError(f"DepthPro checkpoint not found: {checkpoint_path}")
        
        # Python ê²½ë¡œì— DepthPro ì¶”ê°€
        src_path = str(depthpro_base / "src")
        if src_path not in sys.path:
            sys.path.insert(0, src_path)
            logging.info(f"DepthPro ê²½ë¡œ ì¶”ê°€: {src_path}")
        
        logging.info(f"DepthPro ê¸°ë³¸ ê²½ë¡œ: {depthpro_base}")
        logging.info(f"DepthPro ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
    
    def _optimize_gpu_memory(self) -> None:
        """GPU ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
            # CUDA ìµœì í™” ì„¤ì •
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
    
    def _check_gpu_memory(self) -> Tuple[float, float, float]:
        """GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated(0) / 1024**3  # GB
            cached = torch.cuda.memory_reserved(0) / 1024**3      # GB
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
            return allocated, cached, total
        return 0.0, 0.0, 0.0
    
    def _validate_transform(self, transform: Any) -> Union[transforms.Compose, Callable[[Any], torch.Tensor]]:
        """Transform ê°ì²´ íƒ€ì… ê²€ì¦ - 235ì¤„ ì˜¤ë¥˜ í•´ê²°"""
        if not isinstance(transform, (transforms.Compose, Callable)):
            raise TypeError(f"Expected transforms.Compose or callable, got {type(transform)}")
        return transform
    
    def _safe_to_device(self, tensor: torch.Tensor, device: torch.device) -> torch.Tensor:
        """ì•ˆì „í•œ ë””ë°”ì´ìŠ¤ ì´ë™ - 238ì¤„, 257ì¤„ ì˜¤ë¥˜ í•´ê²°"""
        if not torch.is_tensor(tensor):
            raise TypeError(f"Expected torch.Tensor, got {type(tensor)}")
        
        # ì´ë¯¸ ì˜¬ë°”ë¥¸ deviceì— ìˆìœ¼ë©´ ì›ë³¸ ë°˜í™˜
        if tensor.device == device:
            return tensor
        
        # CUDA ê°€ìš©ì„± í™•ì¸
        if 'cuda' in str(device) and not torch.cuda.is_available():
            raise RuntimeError("CUDA not available")
        
        try:
            # ë¹„ë™ê¸° ì „ì†¡ ìµœì í™” (pinned memory â†’ GPU)
            if tensor.is_pinned() and 'cuda' in str(device):
                return tensor.to(device, non_blocking=True)
            return tensor.to(device)
        except Exception as e:
            logging.error(f"Device ì´ë™ ì‹¤íŒ¨: {e}")
            return tensor
    
    def _validate_focal_length(self, f_px: Any) -> Optional[torch.Tensor]:
        """f_px íŒŒë¼ë¯¸í„° ê²€ì¦ ë° ì •ê·œí™” - 257ì¤„ ì˜¤ë¥˜ í•´ê²°"""
        if f_px is None:
            return None
        
        # ìŠ¤ì¹¼ë¼ ê°’ì„ í…ì„œë¡œ ë³€í™˜
        if isinstance(f_px, (int, float)):
            return torch.tensor(f_px, dtype=torch.float32)
        
        # ì´ë¯¸ í…ì„œì¸ ê²½ìš° íƒ€ì… ê²€ì¦
        if torch.is_tensor(f_px):
            if f_px.dtype != torch.float32:
                return f_px.to(torch.float32)
            return f_px
        
        # ê¸°íƒ€ íƒ€ì…ì€ Noneìœ¼ë¡œ ì²˜ë¦¬
        logging.warning(f"Unsupported f_px type: {type(f_px)}, setting to None")
        return None
    
    def _safe_model_infer(self, image_tensor: torch.Tensor, f_px: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """ì•ˆì „í•œ ëª¨ë¸ ì¶”ë¡  - 259ì¤„ ì˜¤ë¥˜ í•´ê²°"""
        if self.model is None:
            raise RuntimeError("Model not loaded")
        
        # ì…ë ¥ ê²€ì¦
        if not torch.is_tensor(image_tensor):
            raise TypeError(f"Expected torch.Tensor, got {type(image_tensor)}")
        
        # í˜•ìƒ ê²€ì¦
        if len(image_tensor.shape) not in [3, 4]:
            raise ValueError(f"Expected 3D or 4D tensor, got shape {image_tensor.shape}")
        
        # ëª¨ë¸ í‰ê°€ ëª¨ë“œ í™•ì¸
        if self.model.training:
            self.model.eval()
        
        # ì•ˆì „í•œ ì¶”ë¡  ì‹¤í–‰
        try:
            with torch.no_grad():
                if f_px is not None:
                    prediction = self.model.infer(image_tensor, f_px=f_px)
                else:
                    prediction = self.model.infer(image_tensor)
                return prediction
        except Exception as e:
            raise RuntimeError(f"Model inference failed: {str(e)}")
    
    def _safe_progress_update(self, iterator: Any, metrics: Dict[str, Any], 
                             update_freq: int = 1) -> None:
        """ì•ˆì „í•œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ - 405ì¤„ ì˜¤ë¥˜ í•´ê²°"""
        try:
            # tqdm ê°ì²´ì¸ì§€ í™•ì¸
            if hasattr(iterator, 'set_postfix') and callable(getattr(iterator, 'set_postfix')):
                # ì—…ë°ì´íŠ¸ ë¹ˆë„ ì œì–´ë¡œ ì„±ëŠ¥ ìµœì í™”
                if hasattr(iterator, 'n') and iterator.n % update_freq == 0:
                    iterator.set_postfix(metrics, refresh=True)
                else:
                    iterator.set_postfix(metrics, refresh=False)
        except (AttributeError, TypeError) as e:
            logging.debug(f"Progress update failed (non-critical): {e}")
        except Exception as e:
            logging.warning(f"Unexpected progress update error: {e}")
    
    def _load_model_official(self) -> None:
        """Apple ê³µì‹ ë°©ë²•ìœ¼ë¡œ DepthPro ëª¨ë¸ ë¡œë“œ"""
        try:
            logging.info("DepthPro ëª¨ë¸ ë¡œë“œ ì‹œì‘ (Apple ê³µì‹ ë°©ë²•)...")
            start_time = time.time()
            
            # Apple ê³µì‹ ë°©ë²•: create_model_and_transforms()
            model, transform = depth_pro.create_model_and_transforms()
            
            # íƒ€ì… ê²€ì¦
            self.transform = self._validate_transform(transform)
            self.model = model.to(self.device)
            
            # í‰ê°€ ëª¨ë“œ ì„¤ì • (Apple ê³µì‹ ê¶Œì¥)
            self.model.eval()
            
            # ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ gradient ë¹„í™œì„±í™”
            for param in self.model.parameters():
                param.requires_grad = False
            
            self.model_loaded = True
            
            load_time = time.time() - start_time
            logging.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Apple ê³µì‹ ë°©ë²•, {load_time:.2f}ì´ˆ)")
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
            allocated, cached, total = self._check_gpu_memory()
            logging.info(f"GPU ë©”ëª¨ë¦¬ - í• ë‹¹: {allocated:.2f}GB / ìºì‹œ: {cached:.2f}GB / ì „ì²´: {total:.2f}GB")
            
            # ëª¨ë¸ ì •ë³´ ì¶œë ¥
            total_params = sum(p.numel() for p in self.model.parameters())
            logging.info(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}")
            
        except Exception as e:
            logging.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            self._provide_troubleshooting_info()
            raise
    
    def _provide_troubleshooting_info(self) -> None:
        """ë¬¸ì œ í•´ê²° ì •ë³´ ì œê³µ"""
        logging.error("DepthPro ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - í•´ê²° ë°©ë²•:")
        logging.error("1. ê°€ìƒí™˜ê²½ í™œì„±í™”: conda activate depth-pro")
        logging.error("2. DepthPro ì„¤ì¹˜: cd depth-pro && pip install -e .")
        logging.error(f"3. ì²´í¬í¬ì¸íŠ¸ í™•ì¸: {CONFIG['checkpoint_path']}")
        logging.error(f"4. ê³µì‹ ì½”ë“œ í™•ì¸: {CONFIG['depthpro_base_dir']}/src/depth_pro")
        logging.error("5. ë©”ëª¨ë¦¬ í™•ì¸: GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œì§€ í™•ì¸")
    
    def _collect_image_files(self, input_dir: Path) -> List[Path]:
        """ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘"""
        image_files = []
        for path in input_dir.iterdir():
            if path.is_file() and path.suffix.lower() in SUPPORTED_FORMATS:
                image_files.append(path)
        return sorted(image_files)  # ì¼ê´€ëœ ìˆœì„œ ë³´ì¥
    
    def _validate_image_file(self, image_path: Path) -> bool:
        """ì´ë¯¸ì§€ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            with Image.open(image_path) as img:
                # ê¸°ë³¸ì ì¸ ì´ë¯¸ì§€ ì •ë³´ í™•ì¸
                _ = img.format, img.size, img.mode
            return True
        except Exception as e:
            logging.warning(f"ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {image_path.name} - {e}")
            return False
    
    def process_image(self, image_path: Union[str, Path], debug: bool = False) -> Dict[str, Any]:
        """Apple ê³µì‹ ë°©ë²•ìœ¼ë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬ - ëª¨ë“  ì˜¤ë¥˜ í•´ê²°"""
        if not self.model_loaded:
            return {
                'success': False,
                'error': 'Model not loaded',
                'image_path': str(image_path)
            }
        
        start_time = time.time()
        image_path_str = str(image_path)
        
        try:
            # ê²½ë¡œ ìœ íš¨ì„± ê²€ì‚¬
            if not Path(image_path_str).exists():
                return {
                    'success': False,
                    'error': f'Image file does not exist: {image_path_str}',
                    'image_path': image_path_str
                }
            
            if debug:
                logging.info(f"ì²˜ë¦¬ ì‹œì‘: {image_path_str}")
            
            # Apple ê³µì‹ ë°©ë²• 1: depth_pro.load_rgb() ì‚¬ìš©
            try:
                image, _, f_px = depth_pro.load_rgb(image_path_str)
                
                if debug:
                    logging.info(f"depth_pro.load_rgb ì„±ê³µ")
                    logging.info(f"ì´ë¯¸ì§€ íƒ€ì…: {type(image)}")
                    logging.info(f"ì´ˆì ê±°ë¦¬ f_px: {f_px}")
                    
            except Exception as e:
                return {
                    'success': False,
                    'error': f'depth_pro.load_rgb failed: {str(e)}',
                    'image_path': image_path_str
                }
            
            # Apple ê³µì‹ ë°©ë²• 2: ê³µì‹ transform ì ìš© - 235ì¤„ ì˜¤ë¥˜ í•´ê²°
            try:
                if self.transform is None:
                    raise RuntimeError("Transform not initialized")
                
                # íƒ€ì… ì•ˆì „í•œ transform í˜¸ì¶œ - 330ì¤„ ë¹¨ê°„ì¤„ í•´ê²°
                # mypyì™€ IDEë¥¼ ìœ„í•œ íƒ€ì… ìºìŠ¤íŒ…
                transform_func = cast(Callable[[Any], torch.Tensor], self.transform)
                image_tensor: torch.Tensor = transform_func(image)
                
                # í…ì„œ íƒ€ì… ê²€ì¦
                if not torch.is_tensor(image_tensor):
                    raise TypeError(f"Transform must return torch.Tensor, got {type(image_tensor)}")
                
                # ì•ˆì „í•œ ë””ë°”ì´ìŠ¤ ì´ë™ - 238ì¤„ ì˜¤ë¥˜ í•´ê²°
                image_tensor = self._safe_to_device(image_tensor, self.device)
                
                if debug:
                    logging.info(f"ê³µì‹ transform í›„ í¬ê¸°: {image_tensor.shape}")
                    logging.info(f"tensor íƒ€ì…: {image_tensor.dtype}")
                    logging.info(f"tensor ë””ë°”ì´ìŠ¤: {image_tensor.device}")
                
            except Exception as e:
                return {
                    'success': False,
                    'error': f'Official transform failed: {str(e)}',
                    'image_path': image_path_str
                }
            
            # f_px ê²€ì¦ ë° ì²˜ë¦¬ - 257ì¤„ ì˜¤ë¥˜ í•´ê²°
            try:
                validated_f_px = self._validate_focal_length(f_px)
                if validated_f_px is not None:
                    validated_f_px = self._safe_to_device(validated_f_px, self.device)
                
                if debug:
                    logging.info(f"f_px ê²€ì¦ ì™„ë£Œ: {validated_f_px}")
                    
            except Exception as e:
                logging.warning(f"f_px ì²˜ë¦¬ ì‹¤íŒ¨, Noneìœ¼ë¡œ ì„¤ì •: {e}")
                validated_f_px = None
            
            # Apple ê³µì‹ ë°©ë²• 3: model.infer() ì‚¬ìš© - 259ì¤„ ì˜¤ë¥˜ í•´ê²°
            try:
                prediction: Dict[str, torch.Tensor] = self._safe_model_infer(image_tensor, validated_f_px)
                
                if debug:
                    logging.info(f"model.infer ì„±ê³µ")
                    logging.info(f"prediction í‚¤: {list(prediction.keys()) if isinstance(prediction, dict) else type(prediction)}")
                
            except Exception as e:
                return {
                    'success': False,
                    'error': f'model.infer failed: {str(e)}',
                    'image_path': image_path_str
                }
            
            # Apple ê³µì‹ ë°©ë²• 4: ê²°ê³¼ ì¶”ì¶œ
            try:
                # Apple ê³µì‹ ë¬¸ì„œì— ë”°ë¥¸ ê²°ê³¼ ì¶”ì¶œ
                depth_map = prediction["depth"]  # Depth in [m]
                focal_length_px = prediction["focallength_px"]  # Focal length in pixels
                
                # Tensorë¥¼ NumPyë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
                if hasattr(depth_map, 'cpu'):
                    depth_map = depth_map.cpu()
                if hasattr(depth_map, 'detach'):
                    depth_map = depth_map.detach()
                if hasattr(depth_map, 'numpy'):
                    depth_map = depth_map.numpy()
                
                # ìŠ¤ì¹¼ë¼ ê°’ ì•ˆì „í•œ ì¶”ì¶œ
                if hasattr(focal_length_px, 'item'):
                    focal_length_px = focal_length_px.item()
                elif hasattr(focal_length_px, 'cpu'):
                    focal_length_px = focal_length_px.cpu().item()
                elif isinstance(focal_length_px, (int, float)):
                    focal_length_px = float(focal_length_px)
                else:
                    focal_length_px = 0.0
                
                # 2D ë°°ì—´ë¡œ ë³€í™˜ (í•„ìš” ì‹œ)
                while depth_map.ndim > 2:
                    depth_map = depth_map[0]
                
                if debug:
                    logging.info(f"ìµœì¢… ê¹Šì´ë§µ í¬ê¸°: {depth_map.shape}")
                    logging.info(f"ê¹Šì´ ë²”ìœ„: {depth_map.min():.4f} ~ {depth_map.max():.4f} m")
                    logging.info(f"ì´ˆì ê±°ë¦¬: {focal_length_px:.2f} px")
                
            except Exception as e:
                return {
                    'success': False,
                    'error': f'Result extraction failed: {str(e)}',
                    'image_path': image_path_str
                }
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            try:
                del image_tensor
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # ì£¼ê¸°ì  ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                self.processed_count += 1
                if self.processed_count % CONFIG["gc_frequency"] == 0:
                    gc.collect()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        
            except Exception as e:
                logging.warning(f"Memory cleanup warning: {str(e)}")
            
            process_time = time.time() - start_time
            
            # ì›ë³¸ ì´ë¯¸ì§€ ì •ë³´ ì•ˆì „í•œ ì²˜ë¦¬ (PIL Image í˜•íƒœë¡œ ë³€í™˜)
            try:
                if hasattr(image, 'size'):
                    original_size = image.size
                    rgb_image = image
                else:
                    # numpy arrayì¸ ê²½ìš° PILë¡œ ë³€í™˜
                    if isinstance(image, np.ndarray):
                        if image.ndim == 3 and image.shape[2] == 3:
                            rgb_image = Image.fromarray((image * 255).astype(np.uint8))
                        else:
                            rgb_image = Image.fromarray(image.astype(np.uint8))
                        original_size = rgb_image.size
                    else:
                        # ê¸°ë³¸ê°’
                        rgb_image = Image.open(image_path_str)
                        original_size = rgb_image.size
            except Exception:
                rgb_image = Image.open(image_path_str)
                original_size = rgb_image.size
            
            return {
                'rgb_image': rgb_image,
                'depth_map': depth_map,
                'focal_length': float(focal_length_px),
                'raw_prediction': prediction,
                'original_size': original_size,
                'process_time': process_time,
                'success': True,
                'image_path': image_path_str
            }
            
        except Exception as e:
            logging.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {image_path_str} - {e}")
            return {
                'success': False,
                'error': str(e),
                'image_path': image_path_str
            }
    
    def process_image_list(self, image_paths: List[Path], show_progress: bool = True) -> List[Dict[str, Any]]:
        """ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬ (ì§„í–‰ë¥  í‘œì‹œ í¬í•¨) - 405ì¤„ ì˜¤ë¥˜ í•´ê²°"""
        results = []
        processing_times = []
        
        iterator = tqdm(image_paths, desc="Apple DepthPro ê¹Šì´ ì¶”ì •", unit="img") if show_progress else image_paths
        
        for i, image_path in enumerate(iterator):
            # ê°œë³„ ì´ë¯¸ì§€ ì²˜ë¦¬ (Apple ê³µì‹ ë°©ë²•)
            result = self.process_image(image_path)
            
            # None ê²°ê³¼ ì²˜ë¦¬
            if result is None:
                result = {
                    'success': False,
                    'error': 'Process returned None',
                    'image_path': str(image_path)
                }
            
            results.append(result)
            
            # ì„±ê³µí•œ ê²½ìš° í†µê³„ ì—…ë°ì´íŠ¸
            if result.get("success", False):
                process_time = result.get("process_time", 0)
                if process_time > 0:
                    processing_times.append(process_time)
                    
                    # ìµœê·¼ 10ê°œ í‰ê· ìœ¼ë¡œ ETA ê³„ì‚°
                    if len(processing_times) >= 10:
                        recent_avg = np.mean(processing_times[-10:])
                    else:
                        recent_avg = np.mean(processing_times)
                    
                    remaining = len(image_paths) - i - 1
                    eta_seconds = remaining * recent_avg
                    
                    # ì•ˆì „í•œ ì§„í–‰ë¥  ì •ë³´ ì—…ë°ì´íŠ¸ - 405ì¤„ ì˜¤ë¥˜ í•´ê²°
                    if show_progress:
                        try:
                            metrics = {
                                'time': f"{process_time:.1f}s",
                                'avg': f"{recent_avg:.1f}s",
                                'ETA': f"{eta_seconds/60:.1f}m",
                                'method': 'Apple Official'
                            }
                            self._safe_progress_update(iterator, metrics, update_freq=5)
                        except Exception as e:
                            logging.debug(f"Progress update failed: {e}")
                    
                    # ëŠë¦° ì²˜ë¦¬ ê²½ê³ 
                    if process_time > 10:
                        logging.warning(f"ì²˜ë¦¬ ì‹œê°„ ê¸¸ìŒ: {image_path.name} - {process_time:.1f}ì´ˆ")
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ ì£¼ê¸°ì  í™•ì¸
            if i % 20 == 0 and i > 0:
                allocated, cached, total = self._check_gpu_memory()
                if allocated > total * 0.9:  # 90% ì´ìƒ ì‚¬ìš© ì‹œ ê²½ê³ 
                    logging.warning(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ: {allocated:.2f}GB / {total:.2f}GB")
        
        return results
    
    def process_single_folder(self, input_dir: Path, output_dir: Path) -> Tuple[int, int, float]:
        """ë‹¨ì¼ í´ë” ì²˜ë¦¬ (Apple ê³µì‹ ë°©ë²•)"""
        
        # í´ë” ì¡´ì¬ í™•ì¸
        if not input_dir.exists():
            logging.error(f"ì…ë ¥ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_dir}")
            return 0, 0, 0.0
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
        image_files = self._collect_image_files(input_dir)
        
        if not image_files:
            logging.warning(f"ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
            return 0, 0, 0.0
        
        logging.info(f"{len(image_files)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
        
        # ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì‚¬
        valid_images = []
        for image_path in image_files:
            if self._validate_image_file(image_path):
                valid_images.append(image_path)
        
        invalid_count = len(image_files) - len(valid_images)
        if invalid_count > 0:
            logging.warning(f"{invalid_count}ê°œ ë¬´íš¨í•œ ì´ë¯¸ì§€ ì œì™¸")
        
        if not valid_images:
            logging.error("ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return 0, 0, 0.0
        
        # ì˜ˆìƒ ì‹œê°„ ê³„ì‚° (Apple ê³µì‹ ë°©ë²•ì€ ë” ë¹ ë¦„)
        estimated_time = len(valid_images) * 1.5 / 60
        logging.info(f"ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time:.1f}ë¶„ (Apple ê³µì‹ ë°©ë²•)")
        
        # ì²˜ë¦¬ ì‹œì‘
        start_time = time.time()
        
        # ê¹Šì´ ì¶”ì • ì‹¤í–‰ (Apple ê³µì‹ ë°©ë²•)
        all_results = self.process_image_list(valid_images, show_progress=True)
        
        # ê²°ê³¼ ì €ì¥
        logging.info("ê²°ê³¼ ì €ì¥ ì¤‘...")
        processed_count = 0
        error_count = 0
        
        save_iterator = tqdm(all_results, desc="ì €ì¥") if len(all_results) > 10 else all_results
        
        for result in save_iterator:
            try:
                if result is not None and result.get("success", False):
                    # image_path ì¶”ì¶œ (ë‹¤ì–‘í•œ í˜•íƒœ ëŒ€ì‘)
                    image_path_value = result.get('image_path')
                    if image_path_value is not None and isinstance(image_path_value, (str, Path)):
                        filename_stem = Path(image_path_value).stem
                    else:
                        filename_stem = f"image_{processed_count}"
                    
                    self.save_depth_results(result, output_dir, filename_stem)
                    processed_count += 1
                else:
                    error_count += 1
                    if result is not None:
                        error_info = result.get('error', 'unknown error')
                        image_info = result.get('image_path', 'unknown path')
                    else:
                        error_info = 'result is None'
                        image_info = 'unknown path'
                    logging.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {image_info} - {error_info}")
            except Exception as e:
                error_count += 1
                logging.error(f"ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        
        process_time = time.time() - start_time
        
        return processed_count, error_count, process_time
    
    def process_all_folders(self) -> Tuple[int, int, float]:
        """ëª¨ë“  í´ë” ì²˜ë¦¬ (ì—¬ì„±, ë‚¨ì„±, ê²€ì¦)"""
        
        # ì „ì²´ ì²˜ë¦¬ í†µê³„
        total_processed = 0
        total_errors = 0
        total_start_time = time.time()
        
        # ê° í´ë”ë³„ ì²˜ë¦¬
        for subdir_idx, subdir in enumerate(CONFIG["subdirs"], 1):
            logging.info(f"\n{'='*60}")
            logging.info(f"[{subdir_idx}/{len(CONFIG['subdirs'])}] {subdir} í´ë” ì²˜ë¦¬ ì‹œì‘")
            logging.info(f"{'='*60}")
            
            # ì…ì¶œë ¥ ê²½ë¡œ ì„¤ì •
            input_dir = CONFIG["base_dir"] / CONFIG["input_folder_base"] / subdir
            output_dir = CONFIG["base_dir"] / CONFIG["output_folder_base"] / subdir
            
            # í´ë” ì¡´ì¬ í™•ì¸
            if not input_dir.exists():
                logging.warning(f"ì…ë ¥ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_dir}")
                continue
            
            # í´ë” ì²˜ë¦¬
            try:
                processed, errors, process_time = self.process_single_folder(input_dir, output_dir)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                total_processed += processed
                total_errors += errors
                
                # í´ë”ë³„ ê²°ê³¼ ì¶œë ¥
                total_images = processed + errors
                avg_time = process_time / total_images if total_images > 0 else 0
                success_rate = (processed / total_images * 100) if total_images > 0 else 0
                
                logging.info(f"\n{subdir} í´ë” ì²˜ë¦¬ ì™„ë£Œ:")
                logging.info(f"  âœ“ ì„±ê³µ: {processed}ê°œ")
                logging.info(f"  âœ— ì‹¤íŒ¨: {errors}ê°œ")
                logging.info(f"  â± ì²˜ë¦¬ ì‹œê°„: {process_time/60:.1f}ë¶„")
                logging.info(f"  ğŸ“Š í‰ê·  ì‹œê°„: {avg_time:.2f}ì´ˆ/ì´ë¯¸ì§€")
                logging.info(f"  ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
                
                # GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
                allocated, cached, total_mem = self._check_gpu_memory()
                logging.info(f"  ğŸ–¥ GPU ë©”ëª¨ë¦¬: {allocated:.2f}GB / {total_mem:.2f}GB")
                
            except Exception as e:
                logging.error(f"{subdir} í´ë” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
            
            # í´ë” ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()
        
        total_time = time.time() - total_start_time
        
        return total_processed, total_errors, total_time
    
    def save_depth_results(self, results: Dict[str, Any], output_dir: Path, filename_stem: str) -> None:
        """ê¹Šì´ ì¶”ì • ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        if not results.get("success", False):
            return
        
        depth_map = results["depth_map"]
        
        # 1. Numpy ë°°ì—´ë¡œ ì €ì¥ (.npy) - ì›ë³¸ ìˆ˜ì¹˜ê°’
        depth_npy_path = output_dir / f"{filename_stem}.npy"
        np.save(depth_npy_path, depth_map)
        
        # 2. ì‹œê°í™”ìš© ì´ë¯¸ì§€ ì €ì¥ (ì„ íƒì )
        if CONFIG.get("save_visualization", True):
            # 2-1. í‘ë°± ê¹Šì´ë§µ (.png)
            depth_gray_path = output_dir / f"{filename_stem}_gray.png"
            
            # 0-255 ë²”ìœ„ë¡œ ì •ê·œí™”
            depth_min, depth_max = depth_map.min(), depth_map.max()
            if depth_max > depth_min:
                depth_normalized = (depth_map - depth_min) / (depth_max - depth_min)
                depth_normalized = 1.0 - depth_normalized # ì—­ì „ ë°©ì§€ìš©
            else:
                depth_normalized = np.zeros_like(depth_map)
            
            depth_gray = (depth_normalized * 255).astype(np.uint8)
            Image.fromarray(depth_gray, mode='L').save(depth_gray_path)
            
            # 2-2. ì»¬ëŸ¬ ê¹Šì´ë§µ (.png) - DepthPro ìŠ¤íƒ€ì¼
            try:
                import matplotlib.pyplot as plt
                import matplotlib.cm as cm
                
                # ì»¬ëŸ¬ë§µ ì˜µì…˜ë“¤
                colormaps = ['viridis', 'plasma', 'inferno', 'magma', 'turbo']
                
                for cmap_name in colormaps:
                    try:
                        # ì»¬ëŸ¬ë§µ ì ìš©
                        colormap = cm.get_cmap(cmap_name)
                        colored_depth = colormap(depth_normalized)
                        
                        # RGBAë¥¼ RGBë¡œ ë³€í™˜ (ì•ŒíŒŒ ì±„ë„ ì œê±°)
                        colored_depth_rgb = (colored_depth[:, :, :3] * 255).astype(np.uint8)
                        
                        # PIL Imageë¡œ ë³€í™˜ í›„ ì €ì¥
                        color_image = Image.fromarray(colored_depth_rgb, mode='RGB')
                        color_path = output_dir / f"{filename_stem}_{cmap_name}.png"
                        color_image.save(color_path)
                        
                    except Exception as e:
                        logging.debug(f"ì»¬ëŸ¬ë§µ {cmap_name} ì €ì¥ ì‹¤íŒ¨: {e}")
                        continue
                
                # ê¸°ë³¸ ì»¬ëŸ¬ ë²„ì „ (magma - Apple DepthPro ì¶”ì • ê¸°ë³¸ê°’) - ë©”ì¸ ì¶œë ¥
                try:
                    main_colormap = cm.get_cmap('magma')
                    main_colored = main_colormap(depth_normalized)
                    main_colored_rgb = (main_colored[:, :, :3] * 255).astype(np.uint8)
                    main_color_image = Image.fromarray(main_colored_rgb, mode='RGB')
                    
                    # ë©”ì¸ ì»¬ëŸ¬ ì´ë¯¸ì§€ ì €ì¥
                    main_color_path = output_dir / f"{filename_stem}.png"
                    main_color_image.save(main_color_path)
                    
                except Exception as e:
                    logging.warning(f"ë©”ì¸ ì»¬ëŸ¬ë§µ ì €ì¥ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ í‘ë°±ìœ¼ë¡œ ëŒ€ì²´
                    Image.fromarray(depth_gray, mode='L').save(output_dir / f"{filename_stem}.png")
            
            except ImportError:
                logging.warning("matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - í‘ë°± ì´ë¯¸ì§€ë§Œ ì €ì¥")
                # matplotlib ì—†ìœ¼ë©´ í‘ë°±ë§Œ ì €ì¥
                Image.fromarray(depth_gray, mode='L').save(output_dir / f"{filename_stem}.png")
            
            except Exception as e:
                logging.warning(f"ì»¬ëŸ¬ ì‹œê°í™” ì‹¤íŒ¨: {e} - í‘ë°±ìœ¼ë¡œ ëŒ€ì²´")
                Image.fromarray(depth_gray, mode='L').save(output_dir / f"{filename_stem}.png")
        
        # 3. ë©”íƒ€ë°ì´í„° JSON ì €ì¥ (ì„ íƒì )
        if CONFIG.get("save_metadata", True):
            depth_min, depth_max = depth_map.min(), depth_map.max()
            metadata = {
                "filename": filename_stem,
                "original_size": results.get("original_size"),
                "depth_shape": list(depth_map.shape),
                "depth_range": {
                    "min": float(depth_min),
                    "max": float(depth_max)
                },
                "process_time": results.get("process_time", 0),
                "focal_length": results.get("focal_length", 0),
                "model_info": {
                    "name": "DepthPro",
                    "method": "Apple Official API",
                    "version": "depth_pro.create_model_and_transforms()",
                    "inference": "model.infer(image, f_px=f_px)",
                    "preprocessing": "depth_pro.load_rgb()"
                },
                "files": {
                    "depth_npy": f"{filename_stem}.npy",
                    "depth_png_color": f"{filename_stem}.png",
                    "depth_png_gray": f"{filename_stem}_gray.png" if CONFIG.get("save_visualization") else None,
                    "depth_png_viridis": f"{filename_stem}_viridis.png" if CONFIG.get("save_visualization") else None,
                    "depth_png_plasma": f"{filename_stem}_plasma.png" if CONFIG.get("save_visualization") else None,
                    "depth_png_inferno": f"{filename_stem}_inferno.png" if CONFIG.get("save_visualization") else None,
                    "depth_png_magma": f"{filename_stem}_magma.png" if CONFIG.get("save_visualization") else None,
                    "depth_png_turbo": f"{filename_stem}_turbo.png" if CONFIG.get("save_visualization") else None
                }
            }
            
            metadata_path = output_dir / f"{filename_stem}.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)


# ===== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ =====
def setup_logging(base_dir: Path) -> None:
    """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
    log_file = base_dir / "depthpro_apple_official_multi.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(str(log_file), encoding='utf-8')
        ],
        force=True
    )


def check_folder_permissions():
    """í´ë” ê¶Œí•œ ë° ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    logging.info("=" * 50)
    logging.info("Apple DepthPro ê³µì‹ ë‹¤ì¤‘ í´ë” í™˜ê²½ í™•ì¸")
    logging.info("=" * 50)
    
    base_dir = CONFIG["base_dir"]
    input_base_dir = base_dir / CONFIG["input_folder_base"]
    output_base_dir = base_dir / CONFIG["output_folder_base"]
    depthpro_base = CONFIG["depthpro_base_dir"]
    checkpoint_path = CONFIG["checkpoint_path"]
    
    logging.info(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬: {base_dir}")
    logging.info(f"ì…ë ¥ ê¸°ë³¸ í´ë”: {input_base_dir}")
    logging.info(f"ì¶œë ¥ ê¸°ë³¸ í´ë”: {output_base_dir}")
    logging.info(f"ì²˜ë¦¬í•  í•˜ìœ„ í´ë”: {CONFIG['subdirs']}")
    logging.info(f"DepthPro ê¸°ë³¸ ê²½ë¡œ: {depthpro_base}")
    logging.info(f"ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
    
    all_good = True
    
    # 1. DepthPro ì„¤ì¹˜ í™•ì¸
    if depthpro_base.exists():
        src_dir = depthpro_base / "src" / "depth_pro"
        egg_info = depthpro_base / "src" / "depth_pro.egg-info"
        
        if src_dir.exists():
            logging.info(f"âœ“ DepthPro ì†ŒìŠ¤ ì½”ë“œ OK: {src_dir}")
        else:
            logging.error(f"âœ— DepthPro ì†ŒìŠ¤ ì½”ë“œ ì—†ìŒ: {src_dir}")
            all_good = False
            
        if egg_info.exists():
            logging.info(f"âœ“ DepthPro ì„¤ì¹˜ ì •ë³´ OK: {egg_info}")
        else:
            logging.warning(f"âš  DepthPro ì„¤ì¹˜ ì •ë³´ ì—†ìŒ: {egg_info}")
    else:
        logging.error(f"âœ— DepthPro ê¸°ë³¸ ê²½ë¡œ ì—†ìŒ: {depthpro_base}")
        all_good = False
    
    # 2. ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    if checkpoint_path.exists():
        file_size = checkpoint_path.stat().st_size / (1024**3)  # GB
        logging.info(f"âœ“ ì²´í¬í¬ì¸íŠ¸ OK: {checkpoint_path} ({file_size:.2f}GB)")
    else:
        logging.error(f"âœ— ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ: {checkpoint_path}")
        all_good = False
    
    # 3. ê¸°ë³¸ ë””ë ‰í† ë¦¬ í™•ì¸
    if not base_dir.exists():
        logging.error(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_dir}")
        return False
    
    # 4. ê° í•˜ìœ„ í´ë” í™•ì¸
    for subdir in CONFIG["subdirs"]:
        input_dir = input_base_dir / subdir
        
        if input_dir.exists():
            try:
                # í´ë” ì½ê¸° ê¶Œí•œ í™•ì¸
                list(input_dir.iterdir())
                image_count = len([f for f in input_dir.iterdir() 
                                 if f.is_file() and f.suffix.lower() in SUPPORTED_FORMATS])
                logging.info(f"âœ“ {subdir} í´ë” OK: {input_dir} (ì´ë¯¸ì§€: {image_count}ê°œ)")
            except PermissionError:
                logging.error(f"âœ— {subdir} í´ë” ê¶Œí•œ ì—†ìŒ: {input_dir}")
                all_good = False
            except Exception as e:
                logging.error(f"âœ— {subdir} í´ë” ì˜¤ë¥˜: {input_dir} - {e}")
                all_good = False
        else:
            logging.warning(f"âš  {subdir} í´ë” ì—†ìŒ: {input_dir}")
    
    # 5. ì¶œë ¥ í´ë” í™•ì¸/ìƒì„±
    try:
        output_base_dir.mkdir(parents=True, exist_ok=True)
        # ì“°ê¸° ê¶Œí•œ í™•ì¸
        test_file = output_base_dir / "test_write.tmp"
        test_file.write_text("test")
        test_file.unlink()
        logging.info(f"âœ“ ì¶œë ¥ ê¸°ë³¸ í´ë” OK: {output_base_dir}")
    except Exception as e:
        logging.error(f"âœ— ì¶œë ¥ ê¸°ë³¸ í´ë” ì˜¤ë¥˜: {output_base_dir} - {e}")
        all_good = False
    
    # 6. DepthPro ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
    try:
        import depth_pro
        logging.info("âœ“ DepthPro ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")
    except ImportError as e:
        logging.error(f"âœ— DepthPro ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        all_good = False
    
    return all_good


# ===== ë©”ì¸ í•¨ìˆ˜ =====
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - Apple DepthPro ê³µì‹ ë°©ë²• ë‹¤ì¤‘ í´ë” ì²˜ë¦¬"""
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(CONFIG["base_dir"])
    
    logging.info("=" * 70)
    logging.info("Apple DepthPro ê³µì‹ ë°©ë²• ë‹¤ì¤‘ í´ë” ì‹œê°í™” ì‹œìŠ¤í…œ ì‹œì‘")
    logging.info("=" * 70)
    
    # í™˜ê²½ ì •ë³´ ì¶œë ¥
    logging.info(f"PyTorch ë²„ì „: {torch.__version__}")
    logging.info(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        logging.info(f"GPU: {torch.cuda.get_device_name(0)}")
    
    logging.info(f"ì²˜ë¦¬í•  í´ë”: {CONFIG['subdirs']}")
    logging.info(f"ì…ë ¥ ê¸°ë³¸ ê²½ë¡œ: {CONFIG['base_dir']}/{CONFIG['input_folder_base']}")
    logging.info(f"ì¶œë ¥ ê¸°ë³¸ ê²½ë¡œ: {CONFIG['base_dir']}/{CONFIG['output_folder_base']}")
    logging.info(f"DepthPro ê²½ë¡œ: {CONFIG['depthpro_base_dir']}")
    logging.info(f"ì²´í¬í¬ì¸íŠ¸: {CONFIG['checkpoint_path']}")
    
    # í™˜ê²½ í™•ì¸
    if not check_folder_permissions():
        logging.error("í™˜ê²½ í™•ì¸ ì‹¤íŒ¨ - ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤")
        return
    
    # Apple DepthPro ê³µì‹ ì‹œê°í™” ëª¨ë¸ ì´ˆê¸°í™” (ì „ì²´ ì²˜ë¦¬ì—ì„œ í•œ ë²ˆë§Œ)
    try:
        visualizer = DepthProOfficialVisualizer()
    except Exception as e:
        logging.error(f"DepthPro ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    if not visualizer.model_loaded:
        logging.error("DepthPro ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # ì „ì²´ ì²˜ë¦¬ í†µê³„
    total_start_time = time.time()
    
    # ëª¨ë“  í´ë” ì²˜ë¦¬ (Apple ê³µì‹ ë°©ë²•)
    try:
        total_processed, total_errors, total_time = visualizer.process_all_folders()
        
        # ì „ì²´ ê²°ê³¼ í†µê³„
        total_images = total_processed + total_errors
        avg_total_time = total_time / total_images if total_images > 0 else 0
        total_success_rate = (total_processed / total_images * 100) if total_images > 0 else 0
        
        logging.info(f"\n{'='*80}")
        logging.info("ğŸ‰ Apple DepthPro ê³µì‹ ë°©ë²• ë‹¤ì¤‘ í´ë” ì²˜ë¦¬ ì™„ë£Œ!")
        logging.info(f"{'='*80}")
        
        logging.info(f"ğŸ“Š ì „ì²´ í†µê³„:")
        logging.info(f"  â€¢ ì´ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {total_images}ê°œ")
        logging.info(f"  â€¢ ì„±ê³µ: {total_processed}ê°œ")
        logging.info(f"  â€¢ ì‹¤íŒ¨: {total_errors}ê°œ")
        logging.info(f"  â€¢ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_time/60:.1f}ë¶„ ({total_time/3600:.2f}ì‹œê°„)")
        logging.info(f"  â€¢ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_total_time:.2f}ì´ˆ/ì´ë¯¸ì§€")
        logging.info(f"  â€¢ ì „ì²´ ì„±ê³µë¥ : {total_success_rate:.1f}%")
        
        # GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
        allocated, cached, total_mem = visualizer._check_gpu_memory()
        logging.info(f"  ğŸ–¥ ìµœì¢… GPU ë©”ëª¨ë¦¬: {allocated:.2f}GB / {total_mem:.2f}GB")
        
    except Exception as e:
        logging.error(f"ë‹¤ì¤‘ í´ë” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return
    
    # ê²°ê³¼ ìš”ì•½
    if total_processed > 0:
        logging.info(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {CONFIG['base_dir']}/{CONFIG['output_folder_base']}")
        
        for subdir in CONFIG["subdirs"]:
            output_dir = CONFIG["base_dir"] / CONFIG["output_folder_base"] / subdir
            if output_dir.exists():
                image_count = len([f for f in output_dir.iterdir() if f.suffix == '.png'])
                logging.info(f"  â”œâ”€â”€ {subdir}/ ({image_count}ê°œ)")
        
        logging.info(f"\nğŸ“„ ìƒì„±ëœ íŒŒì¼ í˜•ì‹ (Apple ê³µì‹ ë°©ë²•):")
        logging.info(f"  â€¢ .npy: ì›ë³¸ ê¹Šì´ ë§µ (numpy ë°°ì—´)")
        if CONFIG.get("save_visualization"):
            logging.info(f"  â€¢ .png: Apple DepthPro ê³µì‹ ì‹œê°í™” (magma ìƒ‰ìƒë§µ)")
            logging.info(f"  â€¢ _gray.png: í‘ë°± ê¹Šì´ë§µ")
            logging.info(f"  â€¢ _magma/plasma/viridis/inferno/turbo.png: ë‹¤ì–‘í•œ ìƒ‰ìƒë§µ")
        if CONFIG.get("save_metadata"):
            logging.info(f"  â€¢ .json: ë©”íƒ€ë°ì´í„° (Apple ê³µì‹ ì •ë³´ í¬í•¨)")
        
        # ì„±ëŠ¥ ë¶„ì„
        if total_time > 0 and total_images > 0:
            images_per_minute = total_images / (total_time / 60)
            logging.info(f"\nâš¡ Apple ê³µì‹ ë°©ë²• ì„±ëŠ¥ ë¶„ì„:")
            logging.info(f"  â€¢ ì²˜ë¦¬ ì†ë„: {images_per_minute:.1f}ê°œ/ë¶„")
            logging.info(f"  â€¢ ë°©ë²•: depth_pro.load_rgb() + model.infer()")
            logging.info(f"  â€¢ ì •í™•ë„: Apple ê³µì‹ API ê¸°ì¤€")
            logging.info(f"  â€¢ ì˜ˆìƒ 1000ê°œ ì²˜ë¦¬ ì‹œê°„: {1000/images_per_minute:.1f}ë¶„")
        
        logging.info("\nâœ… ë‹¤ìŒ ë‹¨ê³„:")
        logging.info("  1. ê²°ê³¼ í™•ì¸: ê° í´ë”ì˜ .png íŒŒì¼ë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”")
        logging.info("  2. í’ˆì§ˆ ê²€ì¦: Apple ê³µì‹ ë°©ë²•ìœ¼ë¡œ ì²˜ë¦¬ëœ ê¹Šì´ ë§µ í’ˆì§ˆì„ í™•ì¸í•´ë³´ì„¸ìš”")
        logging.info("  3. Apple DepthPro ê³µì‹ ì‹œê°í™”: 2x2 ë ˆì´ì•„ì›ƒìœ¼ë¡œ ì „ë¬¸ì  ë¶„ì„")
        logging.info("  4. ë©”íƒ€ë°ì´í„°: .json íŒŒì¼ì—ì„œ Apple ê³µì‹ ì²˜ë¦¬ ì •ë³´ í™•ì¸")
    
    if total_errors > 0:
        logging.warning(f"âš ï¸  {total_errors}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨")
        logging.warning("ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ì‹¤íŒ¨ ì›ì¸ì„ ë¶„ì„í•´ë³´ì„¸ìš”")


# ===== í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ =====
def test_single_image(image_path: Optional[str] = None, debug: bool = True):
    """ë‹¨ì¼ ì´ë¯¸ì§€ Apple ê³µì‹ ë°©ë²• í…ŒìŠ¤íŠ¸"""
    logging.info("=" * 50)
    logging.info("Apple DepthPro ê³µì‹ ë°©ë²• ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸")
    logging.info("=" * 50)
    
    # ì„¤ì • í™•ì¸
    setup_logging(CONFIG["base_dir"])
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • ë˜ëŠ” ìë™ ì°¾ê¸°
    if image_path is None:
        # ìë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì°¾ê¸°
        for subdir in CONFIG["subdirs"]:
            test_folder = CONFIG["base_dir"] / CONFIG["input_folder_base"] / subdir
            if test_folder.exists():
                for ext in ['.jpg', '.jpeg', '.png']:
                    image_files = list(test_folder.glob(f"*{ext}"))
                    if image_files:
                        image_path = str(image_files[0])
                        break
                if image_path:
                    break
        
        if image_path is None:
            logging.error(f"í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
    
    test_image = Path(image_path)
    
    # ê²½ë¡œ í™•ì¸
    if not test_image.exists():
        logging.error(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {test_image}")
        return
    
    # Apple DepthPro ê³µì‹ ì‹œê°í™” ëª¨ë¸ ì´ˆê¸°í™”
    try:
        visualizer = DepthProOfficialVisualizer()
    except Exception as e:
        logging.error(f"Apple DepthPro ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    if not visualizer.model_loaded:
        logging.error("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬ (Apple ê³µì‹ ë°©ë²•)
    logging.info(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_image}")
    result = visualizer.process_image(str(test_image), debug=debug)
    
    if result is not None and result.get("success", False):
        logging.info("âœ… Apple ê³µì‹ ë°©ë²• ì²˜ë¦¬ ì„±ê³µ!")
        depth_map = result.get('depth_map')
        if depth_map is not None:
            logging.info(f"  â€¢ ê¹Šì´ ë§µ í¬ê¸°: {depth_map.shape}")
            depth_min, depth_max = depth_map.min(), depth_map.max()
            logging.info(f"  â€¢ ê¹Šì´ ë²”ìœ„: {depth_min:.4f} ~ {depth_max:.4f} m")
        
        focal_length = result.get('focal_length', 0)
        logging.info(f"  â€¢ Apple ì¶”ì • ì´ˆì ê±°ë¦¬: {focal_length:.2f} px")
        
        process_time = result.get('process_time', 0)
        logging.info(f"  â€¢ ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        output_dir = CONFIG["base_dir"] / "test_output_apple_official_multi"
        try:
            output_dir.mkdir(exist_ok=True, parents=True)
            visualizer.save_depth_results(result, output_dir, "test_depth_apple")
            logging.info(f"  â€¢ ì €ì¥ ìœ„ì¹˜: {output_dir}")
        except Exception as e:
            logging.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        
    else:
        if result is not None:
            error_msg = result.get('error', 'Unknown error')
        else:
            error_msg = 'Process returned None'
        logging.error(f"âŒ Apple ê³µì‹ ë°©ë²• ì²˜ë¦¬ ì‹¤íŒ¨: {error_msg}")


if __name__ == "__main__":
    # ì„¤ì • ë° ë¡œê¹… ì´ˆê¸°í™”
    setup_logging(CONFIG["base_dir"])
    
    # ì‹¤í–‰ ëª¨ë“œ ì„ íƒ
    import sys
    
    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
        
        if mode == "test":
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
            test_image_path: Optional[str] = sys.argv[2] if len(sys.argv) > 2 else None
            test_single_image(test_image_path, debug=True)
            
        elif mode == "check":
            # Apple DepthPro í™˜ê²½ í™•ì¸ ëª¨ë“œ
            check_folder_permissions()
            
        elif mode == "main":
            # ë©”ì¸ ì²˜ë¦¬ ëª¨ë“œ
            if check_folder_permissions():
                main()
            else:
                logging.error("Apple DepthPro í™˜ê²½ í™•ì¸ ì‹¤íŒ¨ - ë©”ì¸ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤")
        else:
            logging.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: {mode}")
            logging.info("ì‚¬ìš©ë²•:")
            logging.info("  python script.py test [image_path]  # Apple ê³µì‹ ë°©ë²• ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸")
            logging.info("  python script.py check             # Apple DepthPro í™˜ê²½ í™•ì¸")
            logging.info("  python script.py main              # Apple ê³µì‹ ë°©ë²• ë‹¤ì¤‘ í´ë” ì²˜ë¦¬")
    else:
        # ê¸°ë³¸ ì‹¤í–‰: Apple DepthPro í™˜ê²½ í™•ì¸ í›„ ë©”ì¸ ì²˜ë¦¬
        logging.info("Apple DepthPro í™˜ê²½ í™•ì¸ ì¤‘...")
        if check_folder_permissions():
            logging.info("Apple DepthPro í™˜ê²½ ì •ìƒ - ë‹¤ì¤‘ í´ë” ì²˜ë¦¬ ì‹œì‘")
            main()
        else:
            logging.error("Apple DepthPro í™˜ê²½ í™•ì¸ ì‹¤íŒ¨")
            logging.info("\në¬¸ì œ í•´ê²° ë°©ë²•:")
            logging.info(f"1. DepthPro ì„¤ì¹˜ í™•ì¸: {CONFIG['depthpro_base_dir']}")
            logging.info(f"2. ì²´í¬í¬ì¸íŠ¸ í™•ì¸: {CONFIG['checkpoint_path']}")
            logging.info(f"3. ì…ë ¥ í´ë”ë“¤ í™•ì¸:")
            for subdir in CONFIG["subdirs"]:
                logging.info(f"   - {CONFIG['base_dir']}/{CONFIG['input_folder_base']}/{subdir}")
            logging.info("4. ê°€ìƒí™˜ê²½ í™œì„±í™”: conda activate depth-pro")
            logging.info("5. í…ŒìŠ¤íŠ¸ ì‹¤í–‰: python script.py test")

# ì‹œê°„ë ë•Œ í•„ìš”ì‹œ ê°ë§ˆ ì¶”ê°€
# https://claude.ai/chat/7de7f942-df97-4499-b455-b2a3e10051dc ì—¬ê¸°ì„œ ì‘ì—…í–ˆìŒ