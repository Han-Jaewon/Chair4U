import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import ndcg_score, precision_score, recall_score, f1_score, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Tuple, List, Dict
import warnings
import copy
warnings.filterwarnings('ignore')

class DataPreprocessor:
    """ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.person_scaler = StandardScaler()
        self.chair_scaler = StandardScaler()
        
    def load_and_preprocess_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        
        # Person ë°ì´í„° ë¡œë“œ
        person_df = pd.read_csv('person.csv')
        print(f"Person ë°ì´í„° í˜•íƒœ: {person_df.shape}")
        print(f"Person ì»¬ëŸ¼: {person_df.columns.tolist()}")
        
        # Chair ë°ì´í„° ë¡œë“œ
        chair_df = pd.read_excel('chair.xlsx')
        print(f"Chair ë°ì´í„° í˜•íƒœ: {chair_df.shape}")
        print(f"Chair ì»¬ëŸ¼: {chair_df.columns.tolist()}")
        
        # Person ë°ì´í„° ì „ì²˜ë¦¬
        person_df = self._preprocess_person_data(person_df)
        
        # Chair ë°ì´í„° ì „ì²˜ë¦¬
        chair_df = self._preprocess_chair_data(chair_df)
        
        return person_df, chair_df
    
    def _preprocess_person_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Person ë°ì´í„° ì „ì²˜ë¦¬"""
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        print("Person ë°ì´í„° ê²°ì¸¡ì¹˜:")
        print(df.isnull().sum())
        
        # ê²°ì¸¡ì¹˜ ë³´ê°„ - í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if df[col].isnull().sum() > 0:
                df[col] = df[col].fillna(df[col].median())
        
        # ì´ë¯¸ì§€ëª… ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì œê±° (ëª¨ë¸ë§ì— ë¶ˆí•„ìš”)
        if 'image-name' in df.columns:
            df = df.drop('image-name', axis=1)
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df.columns = [col.replace(' ', '').replace('-', '_') for col in df.columns]
        
        return df
    
    def _preprocess_chair_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Chair ë°ì´í„° ì „ì²˜ë¦¬"""
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        print("Chair ë°ì´í„° ê²°ì¸¡ì¹˜:")
        print(df.isnull().sum())
        
        # ë²”ìœ„í˜• ë°ì´í„° ì²˜ë¦¬ (MIN, MAX ì»¬ëŸ¼ë“¤)
        processed_df = df.copy()
        
        # MIN, MAX ìŒì„ ì°¾ì•„ì„œ ì¤‘ê°„ê°’ê³¼ ë²”ìœ„ë¡œ ë³€í™˜
        min_cols = [col for col in df.columns if col.endswith('_MIN')]
        max_cols = [col for col in df.columns if col.endswith('_MAX')]
        
        for min_col in min_cols:
            max_col = min_col.replace('_MIN', '_MAX')
            if max_col in df.columns:
                base_name = min_col.replace('_MIN', '')
                
                # ì¤‘ê°„ê°’ ê³„ì‚°
                processed_df[f'{base_name}_mean'] = (df[min_col] + df[max_col]) / 2
                # ë²”ìœ„ ê³„ì‚°
                processed_df[f'{base_name}_range'] = df[max_col] - df[min_col]
                
                # ì›ë³¸ MIN, MAX ì»¬ëŸ¼ ì œê±°
                processed_df = processed_df.drop([min_col, max_col], axis=1)
        
        # ë‹¨ìœ„ ë³€í™˜ (mm â†’ cm)
        numeric_columns = processed_df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            processed_df[col] = processed_df[col] / 10  # mmë¥¼ cmë¡œ ë³€í™˜
        
        # ê²°ì¸¡ì¹˜ ë³´ê°„
        for col in numeric_columns:
            if processed_df[col].isnull().sum() > 0:
                processed_df[col] = processed_df[col].fillna(processed_df[col].median())
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        processed_df.columns = [col.replace(' ', '').replace('-', '_') for col in processed_df.columns]
        
        return processed_df
    
    def create_compatibility_labels(self, person_df: pd.DataFrame, chair_df: pd.DataFrame) -> pd.DataFrame:
        """ë§¤ì¹­ ì¡°ê±´ ê¸°ë°˜ í˜¸í™˜ì„± ë ˆì´ë¸” ìƒì„±"""
        
        # ë§¤ì¹­ ì¡°ê±´ ì •ì˜
        matching_conditions = {
            'A_Buttockpopliteal_length': ('t4_mean', 'less_than'),  # t4 < A
            'B_Popliteal_height': ('h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean', 'approximately'),  # h8 â‰ˆ B
            'C_Hip_breadth': ('b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean', 'greater_than'),  # b3 > C
            'E_Elbow_rest_height': ('h9_ì¢Œì„íŒ”ê±¸ì´_ë†’ì´_mean', 'approximately'),  # h9 â‰ˆ E
            'F_Sitting_height': ('h7_ë“±ë°›ì´_ì„¸ë¡œ_ê¸¸ì´_mean', 'less_than'),  # h7 < F
            'G_Shoulder_breadth': ('b4_ë“±ë°›ì´_ê°€ë¡œ_ê¸¸ì´_mean', 'greater_equal')  # b4 >= G
        }
        
        compatibility_data = []
        
        for person_idx, person_row in person_df.iterrows():
            for chair_idx, chair_row in chair_df.iterrows():
                
                compatibility_score = 0
                condition_scores = {}
                
                for person_feature, (chair_feature, condition_type) in matching_conditions.items():
                    if person_feature in person_row and chair_feature in chair_row:
                        person_val = person_row[person_feature]
                        chair_val = chair_row[chair_feature]
                        
                        # ì¡°ê±´ë³„ ì ìˆ˜ ê³„ì‚°
                        if condition_type == 'less_than':
                            score = 1.0 if chair_val < person_val else max(0, 1 - abs(chair_val - person_val) / person_val)
                        elif condition_type == 'greater_than':
                            score = 1.0 if chair_val > person_val else max(0, 1 - abs(chair_val - person_val) / person_val)
                        elif condition_type == 'greater_equal':
                            score = 1.0 if chair_val >= person_val else max(0, 1 - abs(chair_val - person_val) / person_val)
                        elif condition_type == 'approximately':
                            # 10% ì˜¤ì°¨ í—ˆìš©
                            tolerance = 0.1 * person_val
                            score = 1.0 if abs(chair_val - person_val) <= tolerance else max(0, 1 - abs(chair_val - person_val) / person_val)
                        
                        condition_scores[f'{person_feature}_{chair_feature}'] = score
                        compatibility_score += score
                
                # í‰ê·  í˜¸í™˜ì„± ì ìˆ˜
                avg_compatibility = compatibility_score / len(matching_conditions)
                
                # ë°ì´í„° í–‰ ìƒì„±
                row_data = {
                    'person_id': person_idx,
                    'chair_id': chair_idx,
                    'compatibility_score': avg_compatibility,
                    'label': 1 if avg_compatibility >= 0.7 else 0  # 70% ì´ìƒì´ë©´ í˜¸í™˜
                }
                
                # Person íŠ¹ì„± ì¶”ê°€
                for col in person_df.columns:
                    if col != 'image-name':
                        row_data[f'person_{col}'] = person_row[col]
                
                # Chair íŠ¹ì„± ì¶”ê°€
                for col in chair_df.columns:
                    row_data[f'chair_{col}'] = chair_row[col]
                
                # ì¡°ê±´ë³„ ì ìˆ˜ ì¶”ê°€
                row_data.update(condition_scores)
                
                compatibility_data.append(row_data)
        
        compatibility_df = pd.DataFrame(compatibility_data)
        print(f"í˜¸í™˜ì„± ë°ì´í„° í˜•íƒœ: {compatibility_df.shape}")
        print(f"ê¸ì • ë ˆì´ë¸” ë¹„ìœ¨: {compatibility_df['label'].mean():.3f}")
        
        return compatibility_df

class CIN(nn.Module):
    """Compressed Interaction Network"""
    
    def __init__(self, field_dim: int, embed_dim: int, hidden_layers: List[int]):
        super(CIN, self).__init__()
        self.field_dim = field_dim
        self.embed_dim = embed_dim
        self.hidden_layers = hidden_layers
        
        # CIN ë ˆì´ì–´ë“¤
        self.cin_layers = nn.ModuleList()
        prev_dim = field_dim
        
        for hidden_dim in hidden_layers:
            self.cin_layers.append(
                nn.Conv1d(prev_dim * field_dim, hidden_dim, kernel_size=1)
            )
            prev_dim = hidden_dim
        
        # ì¶œë ¥ ì°¨ì›
        self.output_dim = sum(hidden_layers)
    
    def forward(self, x):
        """
        x: (batch_size, field_dim, embed_dim)
        """
        batch_size = x.size(0)
        x0 = x  # ì›ë³¸ ì„ë² ë”©
        cin_outputs = []
        
        xk = x0
        for layer in self.cin_layers:
            # Outer product ê³„ì‚°
            # xkì™€ x0ì˜ ì™¸ì  ê³„ì‚°
            outer_product = torch.einsum('bfe,bge->bfge', xk, x0)  # (batch, field, field, embed)
            outer_product = outer_product.view(batch_size, -1, self.embed_dim)  # (batch, field*field, embed)
            
            # Convolution ì ìš©
            # (batch, field*field, embed) -> (batch, embed, field*field) -> conv -> (batch, hidden_dim, embed)
            outer_product = outer_product.transpose(1, 2)
            xk = layer(outer_product.view(batch_size, -1, 1)).squeeze(-1)  # (batch, hidden_dim)
            xk = xk.unsqueeze(-1).expand(-1, -1, self.embed_dim)  # (batch, hidden_dim, embed)
            xk = xk.transpose(1, 2)  # (batch, embed, hidden_dim) -> (batch, hidden_dim, embed)
            
            # Sum pooling
            pooled = torch.sum(xk, dim=-1)  # (batch, hidden_dim)
            cin_outputs.append(pooled)
        
        # ëª¨ë“  ë ˆì´ì–´ ì¶œë ¥ ì—°ê²°
        cin_output = torch.cat(cin_outputs, dim=1)  # (batch, sum(hidden_layers))
        return cin_output

class xDeepFM(nn.Module):
    """xDeepFM ëª¨ë¸ (CIN + DNN + Linear)"""
    
    def __init__(self, feature_dims: Dict[str, int], embed_dim: int = 16, 
                 cin_hidden_layers: List[int] = [128, 64], 
                 dnn_hidden_layers: List[int] = [256, 128, 64]):
        super(xDeepFM, self).__init__()
        
        self.feature_dims = feature_dims
        self.embed_dim = embed_dim
        self.total_features = sum(feature_dims.values())
        
        # ì„ë² ë”© ë ˆì´ì–´ë“¤
        self.embeddings = nn.ModuleDict()
        for field_name, field_dim in feature_dims.items():
            self.embeddings[field_name] = nn.Embedding(field_dim, embed_dim)
        
        # Linear part
        self.linear = nn.Linear(self.total_features, 1)
        
        # CIN part
        self.cin = CIN(len(feature_dims), embed_dim, cin_hidden_layers)
        
        # DNN part
        dnn_input_dim = len(feature_dims) * embed_dim
        dnn_layers = []
        prev_dim = dnn_input_dim
        
        for hidden_dim in dnn_hidden_layers:
            dnn_layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.3)
            ])
            prev_dim = hidden_dim
        
        self.dnn = nn.Sequential(*dnn_layers)
        
        # ìµœì¢… ì¶œë ¥ ë ˆì´ì–´
        final_input_dim = 1 + sum(cin_hidden_layers) + prev_dim  # linear + cin + dnn
        self.final_layer = nn.Linear(final_input_dim, 1)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x_dict: Dict[str, torch.Tensor], x_linear: torch.Tensor):
        """
        x_dict: ê° í•„ë“œë³„ ì¸ë±ìŠ¤ í…ì„œ
        x_linear: ì„ í˜• ë¶€ë¶„ìš© ì›ë³¸ íŠ¹ì„±
        """
        
        # Linear part
        linear_out = self.linear(x_linear)
        
        # ì„ë² ë”© ìƒì„±
        embeddings = []
        for field_name, indices in x_dict.items():
            embed = self.embeddings[field_name](indices)
            embeddings.append(embed)
        
        # ì„ë² ë”© ìŠ¤íƒ: (batch_size, num_fields, embed_dim)
        embed_stack = torch.stack(embeddings, dim=1)
        
        # CIN part
        cin_out = self.cin(embed_stack)
        
        # DNN part
        dnn_input = embed_stack.view(embed_stack.size(0), -1)  # flatten
        dnn_out = self.dnn(dnn_input)
        
        # ëª¨ë“  ë¶€ë¶„ ê²°í•©
        final_input = torch.cat([linear_out, cin_out, dnn_out], dim=1)
        output = self.final_layer(final_input)
        
        return self.sigmoid(output)

class DRMRanker:
    """DRM ê¸°ë°˜ Top-K ë­í‚¹ í´ë˜ìŠ¤"""
    
    def __init__(self, temperature: float = 0.5):
        self.temperature = temperature
    
    def differentiable_ranking(self, scores: torch.Tensor) -> torch.Tensor:
        """DRM ê¸°ë²•ì„ ì´ìš©í•œ ì°¨ë³„í™” ê°€ëŠ¥í•œ ë­í‚¹"""
        
        # NeuralSortì˜ relaxed sorting êµ¬í˜„
        n = scores.size(-1)
        
        # Pairwise differences
        diff_matrix = scores.unsqueeze(-1) - scores.unsqueeze(-2)  # (batch, n, n)
        
        # Soft ranking matrix using softmax
        ranking_matrix = torch.softmax(diff_matrix / self.temperature, dim=-1)
        
        # Top-k selection using soft attention
        return ranking_matrix
    
    def get_top_k_recommendations(self, model_scores: torch.Tensor, k: int = 5) -> List[List[int]]:
        """Top-K ì˜ì ì¶”ì²œ"""
        
        batch_size = model_scores.size(0)
        recommendations = []
        
        for i in range(batch_size):
            scores = model_scores[i]
            
            # DRM ranking ì ìš©
            ranking_matrix = self.differentiable_ranking(scores.unsqueeze(0))
            
            # ì ìˆ˜ ê¸°ë°˜ ì •ë ¬
            sorted_indices = torch.argsort(scores, descending=True)
            top_k_indices = sorted_indices[:k].cpu().numpy().tolist()
            
            recommendations.append(top_k_indices)
        
        return recommendations

class ChairRecommendationSystem:
    """ì „ì²´ ì˜ì ì¶”ì²œ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.preprocessor = DataPreprocessor()
        self.model = None
        self.ranker = DRMRanker()
        self.person_df = None
        self.chair_df = None
        self.compatibility_df = None
        
    def prepare_data(self):
        """ë°ì´í„° ì¤€ë¹„"""
        print("=== ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ===")
        self.person_df, self.chair_df = self.preprocessor.load_and_preprocess_data()
        
        print("\n=== í˜¸í™˜ì„± ë ˆì´ë¸” ìƒì„± ===")
        self.compatibility_df = self.preprocessor.create_compatibility_labels(
            self.person_df, self.chair_df
        )
        
        return self.compatibility_df
    
    def prepare_model_data(self, df: pd.DataFrame):
        """ëª¨ë¸ í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„"""
        
        # íŠ¹ì„± ì»¬ëŸ¼ ë¶„ë¦¬
        person_cols = [col for col in df.columns if col.startswith('person_')]
        chair_cols = [col for col in df.columns if col.startswith('chair_')]
        
        # ìˆ˜ì¹˜í˜• íŠ¹ì„±ë“¤
        numeric_features = []
        categorical_features = {}
        
        # Person íŠ¹ì„± ì²˜ë¦¬
        for col in person_cols:
            if df[col].dtype in ['int64', 'float64']:
                numeric_features.append(col)
        
        # Chair íŠ¹ì„± ì²˜ë¦¬  
        for col in chair_cols:
            if df[col].dtype in ['int64', 'float64']:
                numeric_features.append(col)
        
        # ë²”ì£¼í˜• íŠ¹ì„±ì„ ìœ„í•œ ì¸ë±ì‹± (ê°„ë‹¨í•œ êµ¬í˜„ì„ ìœ„í•´ ìƒëµí•˜ê³  ìˆ˜ì¹˜í˜•ë§Œ ì‚¬ìš©)
        X_numeric = df[numeric_features].copy()
        
        # ì •ê·œí™”
        scaler = StandardScaler()
        X_numeric_scaled = scaler.fit_transform(X_numeric)
        X_numeric_scaled = pd.DataFrame(X_numeric_scaled, columns=numeric_features)
        
        # ê°„ë‹¨í•œ íŠ¹ì„± ì¸ë±ì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• í•„ìš”)
        feature_dims = {}
        x_dict = {}
        
        # ìˆ˜ì¹˜í˜• íŠ¹ì„±ì„ êµ¬ê°„ë³„ë¡œ ë‚˜ëˆ„ì–´ ë²”ì£¼í™”
        for i, col in enumerate(numeric_features):
            values = X_numeric_scaled[col].values
            # 10ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì¸ë±ì‹±
            bins = np.percentile(values, np.linspace(0, 100, 11))
            indices = np.digitize(values, bins) - 1
            indices = np.clip(indices, 0, 9)  # 0-9 ë²”ìœ„ë¡œ í´ë¦¬í•‘
            
            feature_dims[col] = 10
            x_dict[col] = torch.tensor(indices, dtype=torch.long)
        
        # ì„ í˜• ë¶€ë¶„ìš© ì›ë³¸ íŠ¹ì„±
        x_linear = torch.tensor(X_numeric_scaled.values, dtype=torch.float32)
        
        # ë ˆì´ë¸”
        y = torch.tensor(df['label'].values, dtype=torch.float32).unsqueeze(1)
        
        return x_dict, x_linear, y, feature_dims, scaler
    
    def train_model(self, df: pd.DataFrame):
        """ëª¨ë¸ í•™ìŠµ (ì†Œê·œëª¨ ë°ì´í„°ì…‹ìš© - í•™ìŠµ/í…ŒìŠ¤íŠ¸ 2-way ë¶„í• )"""
        print("=== ëª¨ë¸ ë°ì´í„° ì¤€ë¹„ ===")
        x_dict, x_linear, y, feature_dims, scaler = self.prepare_model_data(df)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  (80%/20%)
        indices = list(range(len(y)))
        train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42, 
                                             stratify=y.numpy() if len(np.unique(y.numpy())) > 1 else None)
        
        print(f"ë°ì´í„° ë¶„í• : í•™ìŠµ {len(train_idx)}, í…ŒìŠ¤íŠ¸ {len(test_idx)}")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = xDeepFM(
            feature_dims=feature_dims,
            embed_dim=16,
            cin_hidden_layers=[64, 32],
            dnn_hidden_layers=[128, 64, 32]
        )
        
        # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=0.001, weight_decay=1e-5)
        
        print("=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
        
        # í•™ìŠµ ì„¤ì • (ì†Œê·œëª¨ ë°ì´í„°ì— ë§ê²Œ ì¡°ì •)
        num_epochs = 100  # ì—í¬í¬ ìˆ˜ë¥¼ ëŠ˜ë ¤ì„œ ì¶©ë¶„íˆ í•™ìŠµ
        batch_size = min(64, len(train_idx) // 4)  # ì‘ì€ ë°°ì¹˜ ì‚¬ì´ì¦ˆ
        
        # í•™ìŠµ íˆìŠ¤í† ë¦¬
        train_history = {'loss': [], 'accuracy': []}
        
        # ìµœì  ëª¨ë¸ ì €ì¥ìš©
        best_train_loss = float('inf')
        best_model_state = None
        
        for epoch in range(num_epochs):
            # ===== í•™ìŠµ ë‹¨ê³„ =====
            self.model.train()
            epoch_loss = 0
            epoch_correct = 0
            epoch_total = 0
            num_batches = 0
            
            # í•™ìŠµ ë°ì´í„° ì…”í”Œ
            train_indices_shuffled = torch.randperm(len(train_idx))
            
            for i in range(0, len(train_idx), batch_size):
                batch_indices = train_indices_shuffled[i:i+batch_size]
                batch_idx = [train_idx[j] for j in batch_indices]
                
                # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
                batch_x_dict = {}
                for key, tensor in x_dict.items():
                    batch_x_dict[key] = tensor[batch_idx]
                
                batch_x_linear = x_linear[batch_idx]
                batch_y = y[batch_idx]
                
                # Forward pass
                optimizer.zero_grad()
                outputs = self.model(batch_x_dict, batch_x_linear)
                loss = criterion(outputs, batch_y)
                
                # Backward pass
                loss.backward()
                
                # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (ì†Œê·œëª¨ ë°ì´í„°ì—ì„œ ì•ˆì •ì„± í–¥ìƒ)
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                # í†µê³„ ìˆ˜ì§‘
                epoch_loss += loss.item()
                predictions = (outputs > 0.5).float()
                epoch_correct += (predictions == batch_y).sum().item()
                epoch_total += batch_y.size(0)
                num_batches += 1
            
            avg_train_loss = epoch_loss / num_batches
            train_accuracy = epoch_correct / epoch_total
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            train_history['loss'].append(avg_train_loss)
            train_history['accuracy'].append(train_accuracy)
            
            # ìµœì  ëª¨ë¸ ì €ì¥ (í•™ìŠµ ì†ì‹¤ ê¸°ì¤€)
            if avg_train_loss < best_train_loss:
                best_train_loss = avg_train_loss
                best_model_state = copy.deepcopy(self.model.state_dict())
            
            # ë¡œê·¸ ì¶œë ¥ (ë” ë¹ˆë²ˆí•˜ê²Œ)
            if (epoch + 1) % 10 == 0:
                print(f'Epoch [{epoch+1}/{num_epochs}] - ì†ì‹¤: {avg_train_loss:.4f}, ì •í™•ë„: {train_accuracy:.4f}')
        
        # ìµœì  ëª¨ë¸ ë³µì›
        if best_model_state is not None:
            self.model.load_state_dict(best_model_state)
            print(f'ìµœì  ëª¨ë¸ ë³µì› ì™„ë£Œ (ìµœì  í•™ìŠµ ì†ì‹¤: {best_train_loss:.4f})')
        
        # ===== ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€ =====
        print("\n=== ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€ ===")
        self.model.eval()
        test_loss = 0
        test_correct = 0
        test_total = 0
        all_test_outputs = []
        all_test_targets = []
        
        with torch.no_grad():
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
            for i in range(0, len(test_idx), batch_size):
                end_idx = min(i + batch_size, len(test_idx))
                batch_idx = test_idx[i:end_idx]
                
                # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
                batch_x_dict = {}
                for key, tensor in x_dict.items():
                    batch_x_dict[key] = tensor[batch_idx]
                
                batch_x_linear = x_linear[batch_idx]
                batch_y = y[batch_idx]
                
                # Forward pass
                outputs = self.model(batch_x_dict, batch_x_linear)
                loss = criterion(outputs, batch_y)
                
                # í†µê³„ ìˆ˜ì§‘
                test_loss += loss.item() * len(batch_idx)  # ê°€ì¤‘í‰ê· ì„ ìœ„í•´
                predictions = (outputs > 0.5).float()
                test_correct += (predictions == batch_y).sum().item()
                test_total += batch_y.size(0)
                
                # ìƒì„¸ ë¶„ì„ìš© ë°ì´í„° ìˆ˜ì§‘
                all_test_outputs.extend(outputs.cpu().numpy())
                all_test_targets.extend(batch_y.cpu().numpy())
        
        avg_test_loss = test_loss / len(test_idx)
        test_accuracy = test_correct / test_total
        
        print(f'ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:')
        print(f'  ì†ì‹¤: {avg_test_loss:.4f}')
        print(f'  ì •í™•ë„: {test_accuracy:.4f}')
        
        # ì¶”ê°€ í‰ê°€ ì§€í‘œ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ ì¶©ë¶„íˆ í´ ë•Œë§Œ)
        if len(test_idx) > 10:  # ìµœì†Œ 10ê°œ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì´ ìˆì„ ë•Œ
            try:
                from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
                
                test_predictions = np.array(all_test_outputs) > 0.5
                test_targets = np.array(all_test_targets)
                
                # í´ë˜ìŠ¤ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if len(np.unique(test_targets)) > 1:
                    precision = precision_score(test_targets, test_predictions, zero_division=0)
                    recall = recall_score(test_targets, test_predictions, zero_division=0)
                    f1 = f1_score(test_targets, test_predictions, zero_division=0)
                    auc = roc_auc_score(test_targets, all_test_outputs)
                    
                    print(f'  ì •ë°€ë„: {precision:.4f}')
                    print(f'  ì¬í˜„ìœ¨: {recall:.4f}')
                    print(f'  F1 ì ìˆ˜: {f1:.4f}')
                    print(f'  AUC: {auc:.4f}')
                else:
                    print('  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— í•œ í´ë˜ìŠ¤ë§Œ í¬í•¨ë˜ì–´ ìƒì„¸ í‰ê°€ ìƒëµ')
                    
            except Exception as e:
                print(f'  ìƒì„¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}')
        
        # í•™ìŠµ ê³¡ì„  ì‹œê°í™” (ë‹¨ìˆœí™”)
        self._plot_simple_training_curve(train_history)
        
        # ê²°ê³¼ ì €ì¥
        self.train_history = train_history
        self.test_metrics = {
            'loss': avg_test_loss,
            'accuracy': test_accuracy
        }
        
        return self.model, scaler
    
    def _plot_simple_training_curve(self, train_history: Dict):
        """ê°„ë‹¨í•œ í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        epochs = range(1, len(train_history['loss']) + 1)
        
        # ì†ì‹¤ ê³¡ì„ 
        ax1.plot(epochs, train_history['loss'], 'b-', linewidth=2, label='í•™ìŠµ ì†ì‹¤')
        ax1.set_title('í•™ìŠµ ì†ì‹¤ ë³€í™”')
        ax1.set_xlabel('ì—í¬í¬')
        ax1.set_ylabel('ì†ì‹¤')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ì •í™•ë„ ê³¡ì„ 
        ax2.plot(epochs, train_history['accuracy'], 'g-', linewidth=2, label='í•™ìŠµ ì •í™•ë„')
        ax2.set_title('í•™ìŠµ ì •í™•ë„ ë³€í™”')
        ax2.set_xlabel('ì—í¬í¬')
        ax2.set_ylabel('ì •í™•ë„')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('training_curve.png', dpi=300, bbox_inches='tight')
        plt.show()
        print("í•™ìŠµ ê³¡ì„ ì´ 'training_curve.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def recommend_chairs_for_all_users(self, k: int = 5) -> Dict[int, List[Dict]]:
        """ëª¨ë“  ì‚¬ìš©ìì— ëŒ€í•œ Top-K ì˜ì ì¶”ì²œ"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        all_recommendations = {}
        
        print(f"\n=== ëª¨ë“  ì‚¬ìš©ìì— ëŒ€í•œ Top-{k} ì˜ì ì¶”ì²œ ===")
        
        # ê° ì‚¬ìš©ìë³„ë¡œ ì¶”ì²œ ìˆ˜í–‰
        for person_idx, person_row in self.person_df.iterrows():
            print(f"\nì‚¬ìš©ì {person_idx+1} (í‚¤: {person_row['human_height']:.1f}cm) ì¶”ì²œ ì¤‘...")
            
            # ì‚¬ìš©ì íŠ¹ì„± ì¶”ì¶œ
            person_features = {}
            for col in self.person_df.columns:
                if col != 'image-name':  # ì´ë¯¸ì§€ëª… ì œì™¸
                    clean_col = col.replace(' ', '').replace('-', '_')
                    person_features[clean_col] = person_row[col]
            
            # ëª¨ë“  ì˜ìì— ëŒ€í•´ í˜¸í™˜ì„± ì ìˆ˜ ê³„ì‚°
            chair_scores = []
            
            for chair_idx, chair_row in self.chair_df.iterrows():
                # í˜¸í™˜ì„± ì ìˆ˜ ê³„ì‚°
                compatibility_score = self._calculate_compatibility(person_features, chair_row.to_dict())
                
                # ì˜ì ì •ë³´ì™€ ì ìˆ˜ ì €ì¥
                chair_info = chair_row.to_dict()
                chair_info['chair_id'] = chair_idx
                chair_info['compatibility_score'] = compatibility_score
                
                chair_scores.append((chair_idx, compatibility_score, chair_info))
            
            # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ (ë†’ì€ ì ìˆ˜ ìˆœ)
            chair_scores.sort(key=lambda x: x[1], reverse=True)
            
            # Top-K ì¶”ì²œ ìƒì„±
            top_k_recommendations = []
            for i in range(min(k, len(chair_scores))):
                chair_idx, score, chair_info = chair_scores[i]
                
                recommendation = {
                    'rank': i + 1,
                    'chair_id': chair_idx,
                    'compatibility_score': score,
                    'chair_specs': chair_info
                }
                
                top_k_recommendations.append(recommendation)
            
            # ì‚¬ìš©ìë³„ ì¶”ì²œ ê²°ê³¼ ì €ì¥
            all_recommendations[person_idx] = {
                'user_info': person_features,
                'recommendations': top_k_recommendations
            }
            
            # ê° ì‚¬ìš©ìì˜ Top-3 ì¶”ì²œ ì¶œë ¥
            print(f"  Top-3 ì¶”ì²œ ì˜ì:")
            for rec in top_k_recommendations[:3]:
                print(f"    {rec['rank']}ìˆœìœ„: ì˜ì {rec['chair_id']}, í˜¸í™˜ì„±: {rec['compatibility_score']:.3f}")
        
        return all_recommendations
    
    def save_recommendations_to_file(self, recommendations: Dict[int, List[Dict]], filename: str = "chair_recommendations.txt"):
        """ì¶”ì²œ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("=== ê°œì¸ ë§ì¶¤í˜• ì˜ì ì¶”ì²œ ê²°ê³¼ ===\n\n")
            
            for person_idx, user_data in recommendations.items():
                user_info = user_data['user_info']
                user_recommendations = user_data['recommendations']
                
                f.write(f"ğŸ‘¤ ì‚¬ìš©ì {person_idx + 1}\n")
                f.write(f"   í‚¤: {user_info.get('human_height', 'N/A'):.1f}cm\n")
                f.write(f"   í—ˆë²…ì§€ ê¸¸ì´: {user_info.get('A_Buttockpopliteal_length', 'N/A'):.1f}cm\n")
                f.write(f"   ë‹¤ë¦¬ ë†’ì´: {user_info.get('B_Popliteal_height', 'N/A'):.1f}cm\n")
                f.write(f"   ì—‰ë©ì´ ë„ˆë¹„: {user_info.get('C_Hip_breadth', 'N/A'):.1f}cm\n\n")
                
                f.write(f"ğŸª‘ ì¶”ì²œ ì˜ì ëª©ë¡:\n")
                for rec in user_recommendations:
                    f.write(f"   {rec['rank']}ìˆœìœ„: ì˜ì ID {rec['chair_id']}\n")
                    f.write(f"      í˜¸í™˜ì„± ì ìˆ˜: {rec['compatibility_score']:.3f}\n")
                    
                    # ì£¼ìš” ì˜ì ìŠ¤í™ ì¶œë ¥
                    specs = rec['chair_specs']
                    if 'h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean' in specs:
                        f.write(f"      ì¢Œì„ ë†’ì´: {specs['h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean']:.1f}cm\n")
                    if 't4_mean' in specs:
                        f.write(f"      ì¢Œì„ ê¹Šì´: {specs['t4_mean']:.1f}cm\n")
                    if 'b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean' in specs:
                        f.write(f"      ì¢Œì„ ë„ˆë¹„: {specs['b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean']:.1f}cm\n")
                    f.write("\n")
                
                f.write("-" * 50 + "\n\n")
        
        print(f"ì¶”ì²œ ê²°ê³¼ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def create_recommendation_summary(self, recommendations: Dict[int, List[Dict]]) -> pd.DataFrame:
        """ì¶”ì²œ ê²°ê³¼ ìš”ì•½ í…Œì´ë¸” ìƒì„±"""
        
        summary_data = []
        
        for person_idx, user_data in recommendations.items():
            user_info = user_data['user_info']
            user_recommendations = user_data['recommendations']
            
            # ê° ì‚¬ìš©ìì˜ Top-5 ì¶”ì²œì„ í•œ í–‰ìœ¼ë¡œ ì •ë¦¬
            row_data = {
                'user_id': person_idx,
                'user_height': user_info.get('human_height', 0),
                'user_thigh_length': user_info.get('A_Buttockpopliteal_length', 0),
                'user_leg_height': user_info.get('B_Popliteal_height', 0),
            }
            
            # Top-5 ì˜ì IDì™€ ì ìˆ˜ ì¶”ê°€
            for i in range(5):
                if i < len(user_recommendations):
                    rec = user_recommendations[i]
                    row_data[f'top_{i+1}_chair_id'] = rec['chair_id']
                    row_data[f'top_{i+1}_score'] = round(rec['compatibility_score'], 3)
                else:
                    row_data[f'top_{i+1}_chair_id'] = None
                    row_data[f'top_{i+1}_score'] = None
            
            summary_data.append(row_data)
        
        summary_df = pd.DataFrame(summary_data)
        return summary_df
    
    def visualize_recommendations(self, recommendations: Dict[int, List[Dict]]):
        """ì¶”ì²œ ê²°ê³¼ ì‹œê°í™”"""
        
        # ë°ì´í„° ì¤€ë¹„
        user_ids = []
        chair_ids = []
        scores = []
        ranks = []
        
        for person_idx, user_data in recommendations.items():
            for rec in user_data['recommendations']:
                user_ids.append(f'ì‚¬ìš©ì{person_idx+1}')
                chair_ids.append(f'ì˜ì{rec["chair_id"]}')
                scores.append(rec['compatibility_score'])
                ranks.append(rec['rank'])
        
        # íˆíŠ¸ë§µ ìƒì„±
        plt.figure(figsize=(12, 8))
        
        # ì‚¬ìš©ìë³„ Top-5 ì¶”ì²œ ì˜ìì˜ í˜¸í™˜ì„± ì ìˆ˜ íˆíŠ¸ë§µ
        pivot_data = []
        users = []
        
        for person_idx, user_data in recommendations.items():
            user_name = f'ì‚¬ìš©ì{person_idx+1}'
            users.append(user_name)
            
            user_scores = []
            for i in range(5):  # Top-5ë§Œ í‘œì‹œ
                if i < len(user_data['recommendations']):
                    score = user_data['recommendations'][i]['compatibility_score']
                    user_scores.append(score)
                else:
                    user_scores.append(0)
            
            pivot_data.append(user_scores)
        
        pivot_df = pd.DataFrame(pivot_data, 
                               index=users, 
                               columns=[f'1ìˆœìœ„', f'2ìˆœìœ„', f'3ìˆœìœ„', f'4ìˆœìœ„', f'5ìˆœìœ„'])
        
        sns.heatmap(pivot_df, annot=True, cmap='YlOrRd', fmt='.3f', cbar_kws={'label': 'í˜¸í™˜ì„± ì ìˆ˜'})
        plt.title('ì‚¬ìš©ìë³„ Top-5 ì˜ì ì¶”ì²œ í˜¸í™˜ì„± ì ìˆ˜')
        plt.xlabel('ì¶”ì²œ ìˆœìœ„')
        plt.ylabel('ì‚¬ìš©ì')
        plt.tight_layout()
        plt.savefig('recommendation_heatmap.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # í˜¸í™˜ì„± ì ìˆ˜ ë¶„í¬
        plt.figure(figsize=(10, 6))
        plt.hist(scores, bins=20, alpha=0.7, edgecolor='black')
        plt.title('ì „ì²´ ì¶”ì²œ ì˜ìì˜ í˜¸í™˜ì„± ì ìˆ˜ ë¶„í¬')
        plt.xlabel('í˜¸í™˜ì„± ì ìˆ˜')
        plt.ylabel('ë¹ˆë„')
        plt.grid(True, alpha=0.3)
        plt.savefig('compatibility_distribution.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ì‹œê°í™” ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print("- recommendation_heatmap.png: ì‚¬ìš©ìë³„ ì¶”ì²œ íˆíŠ¸ë§µ")
        print("- compatibility_distribution.png: í˜¸í™˜ì„± ì ìˆ˜ ë¶„í¬")
    
    def _calculate_compatibility(self, person_features: Dict, chair_features: Dict) -> float:
        """í˜¸í™˜ì„± ì ìˆ˜ ê³„ì‚°"""
        
        matching_conditions = {
            'A_Buttockpopliteal_length': ('t4_mean', 'less_than'),
            'B_Popliteal_height': ('h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean', 'approximately'),
            'C_Hip_breadth': ('b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean', 'greater_than'),
            'E_Elbow_rest_height': ('h9_ì¢Œì„íŒ”ê±¸ì´_ë†’ì´_mean', 'approximately'),
            'F_Sitting_height': ('h7_ë“±ë°›ì´_ì„¸ë¡œ_ê¸¸ì´_mean', 'less_than'),
            'G_Shoulder_breadth': ('b4_ë“±ë°›ì´_ê°€ë¡œ_ê¸¸ì´_mean', 'greater_equal')
        }
        
        total_score = 0
        valid_conditions = 0
        
        for person_feature, (chair_feature, condition_type) in matching_conditions.items():
            if person_feature in person_features and chair_feature in chair_features:
                person_val = person_features[person_feature]
                chair_val = chair_features[chair_feature]
                
                if condition_type == 'less_than':
                    score = 1.0 if chair_val < person_val else max(0, 1 - abs(chair_val - person_val) / person_val)
                elif condition_type == 'greater_than':
                    score = 1.0 if chair_val > person_val else max(0, 1 - abs(chair_val - person_val) / person_val)
                elif condition_type == 'greater_equal':
                    score = 1.0 if chair_val >= person_val else max(0, 1 - abs(chair_val - person_val) / person_val)
                elif condition_type == 'approximately':
                    tolerance = 0.1 * person_val
                    score = 1.0 if abs(chair_val - person_val) <= tolerance else max(0, 1 - abs(chair_val - person_val) / person_val)
                
                total_score += score
                valid_conditions += 1
        
        return total_score / valid_conditions if valid_conditions > 0 else 0.0

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = ChairRecommendationSystem()
    
    try:
        # ë°ì´í„° ì¤€ë¹„
        compatibility_df = system.prepare_data()
        
        # ëª¨ë¸ í•™ìŠµ
        model, scaler = system.train_model(compatibility_df)
        
        # ì˜ˆì‹œ ì‚¬ìš©ì íŠ¹ì„±
        example_person = {
            'human_height': 170.0,
            'A_Buttockpopliteal_length': 48.0,
            'B_Popliteal_height': 42.0,
            'C_Hip_breadth': 36.0,
            'E_Elbow_rest_height': 24.0,
            'F_Sitting_height': 85.0,
            'G_Shoulder_breadth': 45.0
        }
        
        print("\n=== ì˜ì ì¶”ì²œ ê²°ê³¼ ===")
        recommendations = system.recommend_chairs(example_person, k=5)
        
        for i, rec in enumerate(recommendations, 1):
            print(f"\nì¶”ì²œ {i}ìˆœìœ„:")
            print(f"  ì¶”ì²œ ì ìˆ˜: {rec['recommendation_score']:.3f}")
            print(f"  ì£¼ìš” íŠ¹ì„±:")
                            for key, value in rec.items():
                    if key not in ['recommendation_score', 'rank'] and isinstance(value, (int, float)):
                        print(f"    {key}: {value:.1f}")
        
        print("\n=== í˜¸í™˜ì„± ë¶„ì„ ===")
        # í˜¸í™˜ì„± ë¶„í¬ ì‹œê°í™”
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        plt.hist(compatibility_df['compatibility_score'], bins=30, alpha=0.7)
        plt.title('í˜¸í™˜ì„± ì ìˆ˜ ë¶„í¬')
        plt.xlabel('í˜¸í™˜ì„± ì ìˆ˜')
        plt.ylabel('ë¹ˆë„')
        
        plt.subplot(2, 2, 2)
        label_counts = compatibility_df['label'].value_counts()
        plt.pie(label_counts.values, labels=['ë¹„í˜¸í™˜', 'í˜¸í™˜'], autopct='%1.1f%%')
        plt.title('í˜¸í™˜ì„± ë ˆì´ë¸” ë¶„í¬')
        
        plt.subplot(2, 2, 3)
        person_heights = compatibility_df['person_human_height']
        plt.hist(person_heights, bins=20, alpha=0.7)
        plt.title('ì‚¬ìš©ì í‚¤ ë¶„í¬')
        plt.xlabel('í‚¤ (cm)')
        plt.ylabel('ë¹ˆë„')
        
        plt.subplot(2, 2, 4)
        # í‚¤ì™€ í˜¸í™˜ì„± ì ìˆ˜ì˜ ê´€ê³„
        plt.scatter(person_heights, compatibility_df['compatibility_score'], alpha=0.5)
        plt.title('í‚¤ vs í˜¸í™˜ì„± ì ìˆ˜')
        plt.xlabel('í‚¤ (cm)')
        plt.ylabel('í˜¸í™˜ì„± ì ìˆ˜')
        
        plt.tight_layout()
        plt.savefig('compatibility_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # ë§¤ì¹­ ì¡°ê±´ë³„ ë¶„ì„
        condition_columns = [col for col in compatibility_df.columns if '_mean' in col and col.endswith('_mean')]
        if condition_columns:
            plt.figure(figsize=(15, 10))
            for i, col in enumerate(condition_columns[:6], 1):
                plt.subplot(2, 3, i)
                plt.hist(compatibility_df[col], bins=20, alpha=0.7)
                plt.title(f'{col} ì ìˆ˜ ë¶„í¬')
                plt.xlabel('ì ìˆ˜')
                plt.ylabel('ë¹ˆë„')
            
            plt.tight_layout()
            plt.savefig('condition_scores_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()

# ì¶”ê°€: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ í´ë˜ìŠ¤
class ModelEvaluator:
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        pass
    
    def evaluate_recommendations(self, true_labels: List[List[int]], 
                               predicted_rankings: List[List[int]], 
                               k: int = 5) -> Dict[str, float]:
        """ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€"""
        
        metrics = {}
        
        # Precision@K
        precisions = []
        for true_list, pred_list in zip(true_labels, predicted_rankings):
            if len(pred_list) > 0:
                relevant_items = set(true_list[:k])
                recommended_items = set(pred_list[:k])
                precision = len(relevant_items.intersection(recommended_items)) / len(recommended_items)
                precisions.append(precision)
        
        metrics['precision_at_k'] = np.mean(precisions) if precisions else 0.0
        
        # Recall@K  
        recalls = []
        for true_list, pred_list in zip(true_labels, predicted_rankings):
            if len(true_list) > 0 and len(pred_list) > 0:
                relevant_items = set(true_list[:k])
                recommended_items = set(pred_list[:k])
                recall = len(relevant_items.intersection(recommended_items)) / len(relevant_items)
                recalls.append(recall)
        
        metrics['recall_at_k'] = np.mean(recalls) if recalls else 0.0
        
        # NDCG@K (ê°„ë‹¨í•œ êµ¬í˜„)
        ndcg_scores = []
        for true_list, pred_list in zip(true_labels, predicted_rankings):
            if len(true_list) > 0 and len(pred_list) > 0:
                # DCG ê³„ì‚°
                dcg = 0
                for i, item in enumerate(pred_list[:k]):
                    if item in true_list[:k]:
                        dcg += 1 / np.log2(i + 2)  # i+2 because log2(1) = 0
                
                # IDCG ê³„ì‚° (ì´ìƒì ì¸ DCG)
                idcg = sum(1 / np.log2(i + 2) for i in range(min(k, len(true_list))))
                
                ndcg = dcg / idcg if idcg > 0 else 0
                ndcg_scores.append(ndcg)
        
        metrics['ndcg_at_k'] = np.mean(ndcg_scores) if ndcg_scores else 0.0
        
        return metrics
    
    def print_evaluation_results(self, metrics: Dict[str, float], k: int):
        """í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n=== Top-{k} ì¶”ì²œ ì„±ëŠ¥ í‰ê°€ ===")
        print(f"Precision@{k}: {metrics['precision_at_k']:.4f}")
        print(f"Recall@{k}: {metrics['recall_at_k']:.4f}")  
        print(f"NDCG@{k}: {metrics['ndcg_at_k']:.4f}")

# DRM êµ¬í˜„ ê°œì„ 
class AdvancedDRMRanker:
    """ê°œì„ ëœ DRM ë­í‚¹ í´ë˜ìŠ¤"""
    
    def __init__(self, temperature: float = 0.5):
        self.temperature = temperature
    
    def neural_sort(self, scores: torch.Tensor) -> torch.Tensor:
        """NeuralSortë¥¼ ì´ìš©í•œ ì°¨ë³„í™” ê°€ëŠ¥í•œ ì •ë ¬"""
        
        batch_size, n = scores.shape
        device = scores.device
        
        # Permutation matrix ìƒì„±ì„ ìœ„í•œ ì¤€ë¹„
        scores_expanded = scores.unsqueeze(-1)  # (batch, n, 1)
        scores_transposed = scores.unsqueeze(1)  # (batch, 1, n)
        
        # ëª¨ë“  ìŒì— ëŒ€í•œ ì°¨ì´ ê³„ì‚°
        pairwise_diff = scores_expanded - scores_transposed  # (batch, n, n)
        
        # Relaxed permutation matrix ê³„ì‚°
        P_hat = torch.softmax(pairwise_diff / self.temperature, dim=-1)
        
        return P_hat
    
    def compute_drm_loss(self, scores: torch.Tensor, 
                        true_rankings: torch.Tensor) -> torch.Tensor:
        """DRM ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°"""
        
        # NeuralSortë¥¼ ì´ìš©í•œ soft permutation matrix
        P_hat = self.neural_sort(scores)
        
        # True rankingsë¥¼ one-hotìœ¼ë¡œ ë³€í™˜
        batch_size, n = scores.shape
        true_rankings_one_hot = torch.zeros(batch_size, n, n, device=scores.device)
        
        for b in range(batch_size):
            for i, rank in enumerate(true_rankings[b]):
                if rank < n:  # ìœ íš¨í•œ ë­í‚¹ì¸ ê²½ìš°
                    true_rankings_one_hot[b, i, rank] = 1.0
        
        # MSE ì†ì‹¤ ê³„ì‚°
        loss = torch.mean((P_hat - true_rankings_one_hot) ** 2)
        
        return loss
    
    def get_top_k_with_drm(self, scores: torch.Tensor, k: int = 5) -> torch.Tensor:
        """DRMì„ ì´ìš©í•œ Top-K ì¶”ì¶œ"""
        
        # Soft permutation matrix ê³„ì‚°
        P_hat = self.neural_sort(scores)
        
        # Top-K ìœ„ì¹˜ì˜ ê°€ì¤‘í•© ê³„ì‚°
        batch_size, n = scores.shape
        
        # Top-K ë§ˆìŠ¤í¬ ìƒì„±
        top_k_mask = torch.zeros(n, device=scores.device)
        top_k_mask[:k] = 1.0
        
        # ê° í•­ëª©ì´ Top-Kì— í¬í•¨ë  í™•ë¥  ê³„ì‚°
        top_k_probs = torch.sum(P_hat * top_k_mask.unsqueeze(0).unsqueeze(0), dim=-1)
        
        return top_k_probs

# ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ í´ë˜ìŠ¤
class AdvancedFeatureEngineer:
    """ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
    
    def __init__(self):
        self.feature_importance = {}
        
    def create_interaction_features(self, person_df: pd.DataFrame, 
                                  chair_df: pd.DataFrame) -> pd.DataFrame:
        """ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„±"""
        
        interaction_features = []
        
        for person_idx, person_row in person_df.iterrows():
            for chair_idx, chair_row in chair_df.iterrows():
                
                features = {
                    'person_id': person_idx,
                    'chair_id': chair_idx
                }
                
                # ë¹„ìœ¨ ê¸°ë°˜ íŠ¹ì„±
                if person_row['B_Popliteal_height'] > 0:
                    features['seat_height_ratio'] = chair_row.get('h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean', 0) / person_row['B_Popliteal_height']
                
                if person_row['A_Buttockpopliteal_length'] > 0:
                    features['seat_depth_ratio'] = chair_row.get('t4_mean', 0) / person_row['A_Buttockpopliteal_length']
                
                if person_row['C_Hip_breadth'] > 0:
                    features['seat_width_ratio'] = chair_row.get('b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean', 0) / person_row['C_Hip_breadth']
                
                # ì°¨ì´ ê¸°ë°˜ íŠ¹ì„±
                features['height_diff'] = abs(chair_row.get('h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean', 0) - person_row['B_Popliteal_height'])
                features['depth_diff'] = abs(chair_row.get('t4_mean', 0) - person_row['A_Buttockpopliteal_length'])
                features['width_diff'] = abs(chair_row.get('b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean', 0) - person_row['C_Hip_breadth'])
                
                # BMI ìŠ¤íƒ€ì¼ ë³µí•© ì§€í‘œ
                if person_row['human_height'] > 0:
                    features['body_proportion'] = person_row['F_Sitting_height'] / person_row['human_height']
                
                # ì¡°ì ˆì„± íŠ¹ì„± (ë²”ìœ„ê°€ ìˆëŠ” ê²½ìš°)
                for col in chair_row.index:
                    if col.endswith('_range'):
                        base_name = col.replace('_range', '')
                        features[f'{base_name}_adjustability'] = chair_row[col]
                
                interaction_features.append(features)
        
        return pd.DataFrame(interaction_features)
    
    def calculate_feature_importance(self, model, feature_names: List[str]) -> Dict[str, float]:
        """íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)"""
        
        importance_dict = {}
        
        # ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”ë„ ì¶”ì •
        if hasattr(model, 'linear'):
            linear_weights = model.linear.weight.data.abs().mean().item()
            importance_dict['linear_features'] = linear_weights
        
        if hasattr(model, 'final_layer'):
            final_weights = model.final_layer.weight.data.abs().mean().item()
            importance_dict['combined_features'] = final_weights
        
        return importance_dict

# ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
class RealTimeRecommender:
    """ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, model, chair_df: pd.DataFrame):
        self.model = model
        self.chair_df = chair_df
        self.model.eval()
    
    def quick_recommend(self, user_measurements: Dict[str, float], 
                       k: int = 5, 
                       constraints: Dict = None) -> List[Dict]:
        """ë¹ ë¥¸ ì¶”ì²œ (ì œì•½ ì¡°ê±´ í¬í•¨)"""
        
        recommendations = []
        
        # ì œì•½ ì¡°ê±´ í•„í„°ë§
        filtered_chairs = self.chair_df.copy()
        
        if constraints:
            if 'max_price' in constraints:
                filtered_chairs = filtered_chairs[filtered_chairs.get('price', 0) <= constraints['max_price']]
            
            if 'color_preference' in constraints:
                filtered_chairs = filtered_chairs[filtered_chairs.get('color', '') == constraints['color_preference']]
            
            if 'brand_preference' in constraints:
                filtered_chairs = filtered_chairs[filtered_chairs.get('brand', '') == constraints['brand_preference']]
        
        scores = []
        
        # ë¹ ë¥¸ í˜¸í™˜ì„± ì ìˆ˜ ê³„ì‚°
        for chair_idx, chair_row in filtered_chairs.iterrows():
            compatibility_score = self._quick_compatibility_score(user_measurements, chair_row.to_dict())
            scores.append((chair_idx, compatibility_score, chair_row.to_dict()))
        
        # ì •ë ¬ ë° Top-K ì„ íƒ
        scores.sort(key=lambda x: x[1], reverse=True)
        
        for i in range(min(k, len(scores))):
            chair_idx, score, chair_info = scores[i]
            chair_info['recommendation_score'] = score
            chair_info['rank'] = i + 1
            chair_info['chair_id'] = chair_idx
            recommendations.append(chair_info)
        
        return recommendations
    
    def _quick_compatibility_score(self, user_measurements: Dict[str, float], 
                                 chair_specs: Dict[str, float]) -> float:
        """ë¹ ë¥¸ í˜¸í™˜ì„± ì ìˆ˜ ê³„ì‚°"""
        
        # í•µì‹¬ ë§¤ì¹­ ì¡°ê±´ë§Œ ë¹ ë¥´ê²Œ ê³„ì‚°
        quick_conditions = [
            ('B_Popliteal_height', 'h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean', 'approximately'),
            ('A_Buttockpopliteal_length', 't4_mean', 'less_than'),
            ('C_Hip_breadth', 'b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean', 'greater_than')
        ]
        
        total_score = 0
        valid_conditions = 0
        
        for user_key, chair_key, condition_type in quick_conditions:
            if user_key in user_measurements and chair_key in chair_specs:
                user_val = user_measurements[user_key]
                chair_val = chair_specs[chair_key]
                
                if condition_type == 'approximately':
                    tolerance = 0.15 * user_val  # 15% í—ˆìš©
                    score = 1.0 if abs(chair_val - user_val) <= tolerance else max(0, 1 - abs(chair_val - user_val) / user_val)
                elif condition_type == 'less_than':
                    score = 1.0 if chair_val < user_val else max(0, 1 - (chair_val - user_val) / user_val)
                elif condition_type == 'greater_than':
                    score = 1.0 if chair_val > user_val else max(0, 1 - (user_val - chair_val) / user_val)
                
                total_score += score
                valid_conditions += 1
        
        return total_score / valid_conditions if valid_conditions > 0 else 0.0

# ì‹¤í–‰ ë¶€ë¶„ì— í‰ê°€ ì¶”ê°€
def run_comprehensive_evaluation():
    """ì¢…í•© í‰ê°€ ì‹¤í–‰"""
    
    print("\n" + "="*60)
    print("ì¢…í•© í‰ê°€ ë° ì¶”ê°€ ë¶„ì„")
    print("="*60)
    
    # ëª¨ì˜ ë°ì´í„°ë¡œ í‰ê°€ í…ŒìŠ¤íŠ¸
    evaluator = ModelEvaluator()
    
    # ëª¨ì˜ true labelsì™€ predictions
    true_labels = [
        [0, 1, 2, 3, 4],  # ì‚¬ìš©ì 1ì˜ ì‹¤ì œ ì„ í˜¸ ì˜ìë“¤
        [1, 3, 4, 7, 9],  # ì‚¬ìš©ì 2ì˜ ì‹¤ì œ ì„ í˜¸ ì˜ìë“¤
        [0, 2, 5, 8, 6]   # ì‚¬ìš©ì 3ì˜ ì‹¤ì œ ì„ í˜¸ ì˜ìë“¤
    ]
    
    predicted_rankings = [
        [0, 2, 1, 5, 3],  # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì‚¬ìš©ì 1ì˜ ì¶”ì²œ ìˆœì„œ
        [1, 4, 3, 2, 7],  # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì‚¬ìš©ì 2ì˜ ì¶”ì²œ ìˆœì„œ
        [2, 0, 5, 1, 8]   # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì‚¬ìš©ì 3ì˜ ì¶”ì²œ ìˆœì„œ
    ]
    
    # ë‹¤ì–‘í•œ Kê°’ì— ëŒ€í•´ í‰ê°€
    for k in [3, 5, 10]:
        metrics = evaluator.evaluate_recommendations(true_labels, predicted_rankings, k=k)
        evaluator.print_evaluation_results(metrics, k=k)

def demonstrate_advanced_features():
    """ê³ ê¸‰ ê¸°ëŠ¥ ì‹œì—°"""
    
    print("\n" + "="*60)
    print("ê³ ê¸‰ ê¸°ëŠ¥ ì‹œì—°")
    print("="*60)
    
    # ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œì—°
    print("\n=== ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œì—° ===")
    
    # ëª¨ì˜ ì˜ì ë°ì´í„°
    mock_chair_df = pd.DataFrame([
        {'h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean': 42, 't4_mean': 45, 'b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean': 50, 'price': 300000, 'brand': 'A'},
        {'h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean': 45, 't4_mean': 48, 'b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean': 52, 'price': 500000, 'brand': 'B'},
        {'h8_ì§€ë©´ì¢Œì„_ë†’ì´_mean': 40, 't4_mean': 44, 'b3_ì¢Œì„_ê°€ë¡œ_ê¸¸ì´_mean': 48, 'price': 200000, 'brand': 'C'},
    ])
    
    # ëª¨ì˜ ëª¨ë¸ (ì‹¤ì œë¡œëŠ” í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©)
    class MockModel:
        def eval(self): pass
    
    mock_model = MockModel()
    realtime_recommender = RealTimeRecommender(mock_model, mock_chair_df)
    
    # ì‚¬ìš©ì ì¸¡ì •ê°’
    user_measurements = {
        'B_Popliteal_height': 43.0,
        'A_Buttockpopliteal_length': 47.0,
        'C_Hip_breadth': 49.0
    }
    
    # ì œì•½ ì¡°ê±´
    constraints = {
        'max_price': 400000,
        'brand_preference': 'A'
    }
    
    recommendations = realtime_recommender.quick_recommend(
        user_measurements, 
        k=3, 
        constraints=constraints
    )
    
    print("ì¶”ì²œ ê²°ê³¼:")
    for rec in recommendations:
        print(f"  ìˆœìœ„ {rec['rank']}: ì ìˆ˜ {rec['recommendation_score']:.3f}, ë¸Œëœë“œ {rec.get('brand', 'N/A')}")

if __name__ == "__main__":
    # ë©”ì¸ ì‹¤í–‰
    main()
    
    # ì¢…í•© í‰ê°€ ì‹¤í–‰
    run_comprehensive_evaluation()
    
    # ê³ ê¸‰ ê¸°ëŠ¥ ì‹œì—°
    demonstrate_advanced_features()
    
    print("\n" + "="*60)
    print("ì˜ì ì¶”ì²œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
    print("ìƒì„±ëœ íŒŒì¼:")
    print("- compatibility_analysis.png")
    print("- condition_scores_analysis.png")
    print("="*60)
                